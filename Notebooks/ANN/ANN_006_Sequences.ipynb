{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ANN_006_Sequences.ipynb","provenance":[{"file_id":"https://github.com/abidlabs/deep-learning-genomics-primer/blob/master/A_Primer_on_Deep_Learning_in_Genomics_Public.ipynb","timestamp":1646747740505}],"collapsed_sections":["bSxjSBNjYdu2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"R46-rwd4hNMn"},"cell_type":"markdown","source":["# Sequence Analysis with Neural Networks"]},{"metadata":{"id":"eiiwjw4yhX0P"},"cell_type":"markdown","source":["This lecture is based on a Nature Genetics tutorial:\n","\n","- **A Primer on Deep Learning in Genomics**, Zou et al. Nature Genetics 2018 [link](https://www.nature.com/articles/s41588-018-0295-5).\n","- notebook: https://colab.research.google.com/github/abidlabs/deep-learning-genomics-primer/blob/master/A_Primer_on_Deep_Learning_in_Genomics_Public.ipynb"]},{"metadata":{"id":"QABdxctitugX"},"cell_type":"markdown","source":["# Background: Models for Transcription Factor Binding"]},{"cell_type":"markdown","source":["\n","<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/ANN_TF_Bucher2020.png\",  width=\"500\">\n","</div>\n","(from Bucher 2020)"],"metadata":{"id":"c74ZVcVCy8UZ"}},{"cell_type":"markdown","source":["\n","- short stretches (5-10 bp) of prefered DNA sequences\n","- binding energy models (physics)\n","- scoring models (statistics)\n","- **observations**\n","  - 1980 - 2000: small number (10-20) of known binding sites (heavily studied, databases)\n","  - since 2008: large scale experiments (ChIP-seq): thousands of binding sites\n","\n","Below we will address this problem from a neural network perspective.\n","The main goal will be to derive a classifier to discriminate\n","*bound* sequences from *non-bound* sequences.\n","\n","**Notice:** binding $\\ne$ funcional binding\n","\n","**Discussion:**\n","How should we define the input data (x) and output data (y)?"],"metadata":{"id":"ns_SzuTZ9cH3"}},{"cell_type":"markdown","source":["# Load Libraries"],"metadata":{"id":"bSxjSBNjYdu2"}},{"cell_type":"code","source":["!pip install Bio"],"metadata":{"id":"Gi4yMy5K8odD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.metrics import confusion_matrix\n","\n","\n","import requests\n","import random\n","from Bio import SeqIO\n","from io import StringIO\n","\n","# my plot function for confusion matrix\n","def plot_cm(mat):\n","  classes = np.arange(cm.shape[0])\n","  plt.imshow(mat, cmap=plt.cm.Blues)\n","  for (j,i),label in np.ndenumerate(mat):\n","    plt.text(i,j,np.round(label,2),ha='center',va='center')\n","\n","  plt.colorbar()\n","  plt.title('Confusion Matrix')\n","  plt.xlabel('True label')\n","  plt.ylabel('Pred label')\n","  plt.xticks(classes)\n","  plt.yticks(classes)\n","  plt.show()\n","\n","print('tensorflow: ', tf.__version__)"],"metadata":{"id":"ND1lnm-PQeF_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Read Data (sequences)"],"metadata":{"id":"6kXJTimOMl6i"}},{"cell_type":"markdown","source":["Here we read a fasta file with **positive** sequences = target sequences of the transcription factor of interest."],"metadata":{"id":"g3hxkX5nMtGh"}},{"cell_type":"code","source":["#url='https://jaspar.genereg.net/download/data/2022/sites/MA0036.2.sites' # the original\n","url='https://github.com/thomasmanke/ABS/raw/main/data/MA0036.2.sites'     # a copy\n","data = requests.get(url).text\n","\n","seq_pos = []\n","for s in SeqIO.parse(StringIO(data), \"fasta\"):\n","  seq_pos.append(str(s.seq))\n","\n","print('Read {} target sequences'.format(len(seq_pos)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RO2Jgle4syGI","executionInfo":{"status":"ok","timestamp":1655661278474,"user_tz":-120,"elapsed":1116,"user":{"displayName":"Thomas Manke","userId":"17591636328965298454"}},"outputId":"698fe9f3-af42-4a73-d4ea-a562151f1593"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Read 4380 target sequences\n"]}]},{"cell_type":"markdown","source":["# Clean Data"],"metadata":{"id":"_s3MuTz2uPjb"}},{"cell_type":"markdown","source":["There is always some cleaning to be done (could have been done above)"],"metadata":{"id":"ggc7MHP-xr0L"}},{"cell_type":"code","source":["# capitalize all letters\n","seq_pos = [ s.upper() for s in seq_pos ]  \n","\n","# in this example all sequences have the same length\n","# in general we would probably have to trim and or pad the sequences here\n","L = [len(item) for item in seq_pos]\n","plt.hist(L)\n","plt.show()"],"metadata":{"id":"c4Z8b56xrEkZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Negative Dataset"],"metadata":{"id":"Oyj28I4nx7Uw"}},{"cell_type":"markdown","source":["Ideally we would like to have a set of non-target sequences.\n","In the absence of such a set, we define our own negative dataset by shuffeling. "],"metadata":{"id":"9c-dTEXOyAT3"}},{"cell_type":"code","source":["# define negative sequences (non targets)\n","seq_neg = [ ''.join(random.sample(s, len(s)) ) for s in seq_pos ]\n","\n","# merge positive and negative sequences\n","seq = seq_pos + seq_neg\n","\n","# define the corresponding labels (1=target, 0=non-target)\n","lab = [1]*len(seq_pos) + [0]*len(seq_neg)"],"metadata":{"id":"T9jSfuSfyJBr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Encoding"],"metadata":{"id":"ygUMIX5JV59E"}},{"cell_type":"code","source":["nuc2int = {\n","    \"A\": 0,\n","    \"C\": 1,\n","    \"T\": 2,\n","    \"G\": 3,\n","    \"N\": 4,\n","}\n","\n","int2nuc = dict((v, k) for k, v in nuc2int.items())\n","\n","# integer encoding: A->0, C->1, ...\n","seq_i = [[nuc2int[letter] for letter in s] for s in seq]\n","\n","# one-hot encoding: 0 -> [ 1 0 0 0 0], 1-> [0 1 0 0 0], ... \n","seq_h = tf.one_hot(seq_i,depth=5, dtype=tf.float32)\n","\n","lab_i = np.array(lab).reshape(-1,1)                 # integer encoding: list --> numpy\n","lab_h = tf.one_hot(lab,depth=2, dtype=tf.float32)   # one-hot encoded: list -> tf.EagerTensor \n","print(lab_i.shape, lab_h.shape)\n","print(type(lab_i), type(lab_h))"],"metadata":{"id":"iyxQi77Js8sW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Split Data: Train & Test"],"metadata":{"id":"Ea6ur9XgOcxf"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","seq_h=np.array(seq_h)  # tf --> numpy\n","lab_h=np.array(lab_h)  # tf  --> numpy\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","  seq_h, lab_h, test_size=0.20, random_state=42)\n","\n","print('X_train:    ', X_train.shape)\n","print('y_train:    ', y_train.shape)\n","print('train-test: ', len(y_train), len(y_test))"],"metadata":{"id":"yPWSiZ-0Oe3Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define Model"],"metadata":{"id":"nlG8ovdYN_aC"}},{"cell_type":"code","source":["from tensorflow.keras.layers import Conv1D, Dense, MaxPooling1D, Flatten\n","from tensorflow.keras.models import Sequential\n","\n","# Define input shape and output dimensions - for each sample\n","x_s = X_train.shape[1:] # feature (x) shape (skip first sample axis [0])\n","nc = y_train.shape[1]   # number of classes (=1 without one-hot encoding)\n","\n","l_name='binary_crossentropy' \n","a_name='binary_accuracy'\n","\n","model = Sequential(name='Nanog_CNN_1')\n","model.add(Conv1D(filters=32, kernel_size=12, input_shape=x_s))\n","model.add(MaxPooling1D(pool_size=4))\n","model.add(Flatten())\n","model.add(Dense(16, activation='relu'))\n","model.add(Dense(nc, activation='softmax')) \n","\n","model.compile(optimizer='adam', loss=l_name, metrics=a_name)\n","\n","model.summary()"],"metadata":{"id":"4RXPkpSerpcJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fit Model"],"metadata":{"id":"f0-cDYYhbQFP"}},{"cell_type":"code","source":["fh = model.fit(X_train, y_train, epochs=20, verbose=1, validation_split=0.1)\n","model_fn   = model.name + '.h5'\n","history_fn = model.name + '_history.npy'\n","\n","model.save(model_fn)      # save model\n","np.save(history_fn, fh)   # save history"],"metadata":{"id":"1w3xOuMBbRi3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"3nqxH71XbZ7F"}},{"cell_type":"code","source":["%%script echo run if necessary\n","model_fn   = model.name + '.h5'\n","history_fn = model.name + '_history.npy'\n","model = tf.keras.models.load_model(model_fn)        # load model\n","fh = np.load(history_fn, allow_pickle=True).item()  # load history"],"metadata":{"id":"1njTE-kZbbWk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655661402013,"user_tz":-120,"elapsed":177,"user":{"displayName":"Thomas Manke","userId":"17591636328965298454"}},"outputId":"95211799-4844-481f-f18a-a827b3d7d3be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["run if necessary\n"]}]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"1obwpgIRFSiY"}},{"cell_type":"code","source":["print('Evaluate Model:',model.name)\n","test_loss, test_acc = model.evaluate(X_test, y_test)\n","\n","val_a_name = 'val_' + a_name\n","plt.plot(fh.history['loss'])\n","plt.plot(fh.history['val_loss'])\n","plt.axhline(y=test_loss, color='green', linestyle='-.',label = 'test')\n","plt.show()\n","\n","plt.plot(fh.history[a_name])\n","plt.plot(fh.history[val_a_name])\n","plt.axhline(y=test_acc, color='green', linestyle='-.',label = 'test')\n","plt.show()"],"metadata":{"id":"48qq3Ld1bnha"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Predictions"],"metadata":{"id":"-QY9EbDNlYat"}},{"cell_type":"code","source":["pred=model.predict(X_test)             # predicted class probabilities\n","pred_class = np.argmax(pred,axis=1)    # predicted classes\n","true_class = np.argmax(y_test,axis=1)  # true classes: one-hot encoded\n","\n","cm=confusion_matrix(pred_class, true_class)\n","plot_cm(cm)"],"metadata":{"id":"SgSlXB-blavy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Interpretations: Saliency Maps"],"metadata":{"id":"rV0CesgYm3gZ"}},{"cell_type":"markdown","source":["So the classification accuracy appears very high. \n","\n","**Discussion:** Should we be concerned?\n","\n","Now we want to understand which part of the sequence contributed most to the given classification (target/non-target)\n","\n","Question: \n","Which part of the input data contributes most strongly"],"metadata":{"id":"ltG8EczU1Imp"}},{"cell_type":"code","source":["! pip install tf-keras-vis"],"metadata":{"id":"IP_XXJJydC6i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tf_keras_vis.saliency import Saliency\n","from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n","from tf_keras_vis.utils.scores import CategoricalScore\n","\n","saliency = Saliency( model, model_modifier=ReplaceToLinear(), clone=True)\n","\n","s_id = 42                                  # select sequence id\n","s_seq = X_test[s_id]                       # selected sequence (one hot encoded)\n","s_int = np.argmax(s_seq,axis=1)            # convert to integer\n","s_chr = list(map(int2nuc.get, s_int))      # map integer to DNA letters\n","\n","s_class = pred_class[s_id]  # predicted class for s_id\n","t_class = true_class[s_id]  # true class for s_id\n","\n","score = CategoricalScore(s_class)\n","sm    = saliency(score, s_seq)      # saliency map for one sequence\n","L     = sm.shape[1]                 # length of sequence\n","\n","### plot  salience\n","plt.figure(figsize=[20,6])\n","barlist = plt.bar(np.arange(L), sm[0])\n","plt.xlabel('Bases')\n","plt.ylabel('Saliency')\n","plt.title('sequence id: {} true label: {} pred label: {} '.format(s_id, t_class, s_class))\n","plt.xticks(np.arange(L), list(s_chr))\n","plt.show()"],"metadata":{"id":"-7cwPueLdEyx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compare the Saliency Map with the known logo here: https://jaspar.genereg.net/matrix/MA0036.2/"],"metadata":{"id":"Q4X4MEbZpNOA"}}]}