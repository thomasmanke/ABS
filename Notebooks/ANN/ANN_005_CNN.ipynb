{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ANN_005_CNN.ipynb","provenance":[],"collapsed_sections":["_5H1VxaENAex","t36NjcvJNdtM","o5pP7LqKM_Ta","8eDUvg-0OIzK","pdNz64M2LZpD","AQ-tk-AUu81J"],"authorship_tag":"ABX9TyMC0zUas0sMA6cL4VVUkLxp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## Get Libraries"],"metadata":{"id":"_5H1VxaENAex"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","print('tf-version: ', tf.__version__)\n","\n","# my plot function for confusion matrix\n","def plot_cm(mat):\n","  classes = np.arange(cm.shape[0])\n","  plt.imshow(mat, cmap=plt.cm.Blues)\n","  for (j,i),label in np.ndenumerate(mat):\n","    plt.text(i,j,np.round(label,2),ha='center',va='center')\n","\n","  plt.colorbar()\n","  plt.title('Confusion Matrix')\n","  plt.xlabel('True label')\n","  plt.ylabel('Pred label')\n","  plt.xticks(classes)\n","  plt.yticks(classes)\n","  plt.show()"],"metadata":{"id":"Q40zhW1fNDoZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Convolution Neural Network"],"metadata":{"id":"ii-YhU6h-m5O"}},{"cell_type":"markdown","source":["## Challenges from previous work (MNIST)\n","\n","\n","\n","\n"],"metadata":{"id":"ZuqQ0SN81vlR"}},{"cell_type":"markdown","source":["<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/smileys.png\",  width=\"400\">\n","</div>\n","\n","\n","\n"],"metadata":{"id":"ahRHyzeDTsv6"}},{"cell_type":"markdown","source":["- training (and test) data were highly structured: \n","- fixed size\n","- grey scale\n","- item centered\n","- only single item \n","\n","**Discussion**: \n","Other possible challenges?\n","- ...\n","- ...\n","-"],"metadata":{"id":"QE-MGtt-QMbX"}},{"cell_type":"markdown","source":["Algorithms should be:\n","\n","- robuts to those changes within one class (e.g. cat)\n","- generic and transferable to all other classes \n","- interpretable"],"metadata":{"id":"kA9XHD3LPkt-"}},{"cell_type":"markdown","source":["## A short history"],"metadata":{"id":"ov6w6t23K9RY"}},{"cell_type":"markdown","source":["Algorithms, Compute Power, Data, Data & Data\n","\n","- 1958 Rosenblatt: The perceptron: A probabilistic Model for Information Storage and  Organization in the Brain.\n","- 1998 Le Cun et al.  (MNIST):  60000 images of 10 handwritten digits ($10^7$ pixels) + CPU ($10^6$ transitors)\n","- 2012 Alex Krizhevsky et al (ImageNet): 1.3M images for 1000 classes ($10^{14}$ pixels) + GPU ($10^9$ transistors)\n","- 2021 Yang et al. (MedMNIST): 700k images for 2-11 classes \n","https://github.com/MedMNIST/MedMNIST\n","- 2022 Google Open Images v6: 60M images, 20000 classes: https://storage.googleapis.com/openimages/web/index.html\n","\n"],"metadata":{"id":"6XgVoYCGx69o"}},{"cell_type":"markdown","source":["## Another classical dataset: CIFAR-10\n","\n","This is a set of 50k images in 10 categories.\n","They are rather coarse (32 x 32), but unlike MNIST (Handwritten Digits) they are not as standardized.\n","\n"],"metadata":{"id":"RVWuw94zLK49"}},{"cell_type":"code","source":["# cell takes 1-2 minutes (on my regular home network)\n","cifar10 = tf.keras.datasets.cifar10\n","(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n","\n","# normalization\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# just for easier reference to replace integers with names\n","class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n","               'dog', 'frog', 'horse', 'ship', 'truck']"],"metadata":{"id":"SfjAKB6rAq2P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Group Task (40 min): Explore, Model, Fit, Evaluate"],"metadata":{"id":"DULbgSPVNSb6"}},{"cell_type":"markdown","source":["## Explore"],"metadata":{"id":"t36NjcvJNdtM"}},{"cell_type":"markdown","source":["## A Simple Neural Network"],"metadata":{"id":"ocFIL5V5p5ZG"}},{"cell_type":"markdown","source":["... you might copy one from handwritten digits"],"metadata":{"id":"gl0aZHnkNmoc"}},{"cell_type":"code","source":["\n"],"metadata":{"id":"eHDHQ3Ewpo0q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fit & Evaluate"],"metadata":{"id":"o5pP7LqKM_Ta"}},{"cell_type":"code","source":[""],"metadata":{"id":"6gvIneh9qZvC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Report back and Discussion (15 min)"],"metadata":{"id":"8eDUvg-0OIzK"}},{"cell_type":"markdown","source":["# CNN: A picture and some jargon"],"metadata":{"id":"pdNz64M2LZpD"}},{"cell_type":"markdown","source":["![CNN_convlayer](https://upload.wikimedia.org/wikipedia/commons/6/68/Conv_layer.png)\n","(from wikipedia.org)"],"metadata":{"id":"P27CBX0kuFqC"}},{"cell_type":"markdown","source":["### Filters"],"metadata":{"id":"AQ-tk-AUu81J"}},{"cell_type":"markdown","source":["![filter](https://wiki.tum.de/download/attachments/23572254/cnn6.png)\n","(from wiki.tum.de)"],"metadata":{"id":"PJm89Rh3vAIy"}},{"cell_type":"markdown","source":["- input layer: image shape [w,h,3]\n","- convolutional layer (Conv): filters\n","\n","  - detect pattern (e.g. horizontal, vertical, diagonal lines)\n","  - have the same depth as input: 28x28x3 --> 5x5x6 \n","  - several filter per layer: different filters applied to same spatial location in image\n","\n","- pooling filter (Pool): spatially downsampling, depth stay the same (e.g. max or average)\n","\n","Lower layers: Primitive concepts\n","\n","Higher layers: Higher order concepts (reasoning on top of edge maps)\n"],"metadata":{"id":"Wma7ne7z5IDr"}},{"cell_type":"markdown","source":["## CNN: tensorflow implementation"],"metadata":{"id":"gJ1knw8lLrre"}},{"cell_type":"code","source":["nc = np.unique(y_train).size  # number of classes / labels in training set\n","l_name = 'sparse_categorical_crossentropy'\n","a_name = 'sparse_categorical_accuracy'\n","\n","input_shape = X_train.shape[1:]\n","\n","print('X_train.shape:     ', X_train.shape)\n","print('input_shape:       ', input_shape)\n","print('number of classes: ', nc)\n","\n","model = tf.keras.models.Sequential(name='CNN')\n","\n","# Convolutional layers\n","model.add(tf.keras.layers.InputLayer(input_shape))\n","model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', name='first_conv'))\n","model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n","\n","#model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n","#model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n","#model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n","\n","# as before\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(64, activation='relu', name='last'))\n","model.add(tf.keras.layers.Dense(nc, activation='softmax', name='output'))\n","\n","model.compile(optimizer='adam', loss=l_name, metrics=a_name)\n","model.summary()"],"metadata":{"id":"BJ-yuN7WDtIL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CNN: fitting and time for some theory"],"metadata":{"id":"TMKzfHI_LzH8"}},{"cell_type":"markdown","source":["The following cell will fit the model. This will take some time - especially without dedicated hardware (e.g. GPU) or further optimization (improved algorithm).\n","\n","Please start the cell. While it runs I will provide some explanations what is going on under the hood."],"metadata":{"id":"N7uBGacBNVs2"}},{"cell_type":"code","source":["fh = model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n","\n","plt.plot(fh.history['loss'])\n","plt.plot(fh.history['val_loss'])\n","plt.show()"],"metadata":{"id":"Q0ESfsnFFwvR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Saving the model"],"metadata":{"id":"xLGQRxHiN7Sl"}},{"cell_type":"code","source":["# Save the model. Choose suitable path and name. \n","model.save('my_cifar10_model')\n","\n","# Load the model (use latter)\n","model = tf.keras.models.load_model(\"my_cifar10_model\")"],"metadata":{"id":"zi5EhbG0OZmF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluations"],"metadata":{"id":"KWRzo3588PdX"}},{"cell_type":"code","source":["eval = model.evaluate(X_test,  y_test)\n","print('evaluation ',eval)\n","test_acc = eval[1]\n","\n","## Plotting history and test accuracy\n","plt.plot(fh.history['accuracy'], label='train accuracy')\n","plt.plot(fh.history['val_accuracy'], label = 'valid accuracy')\n","plt.axhline(y=test_acc, color='green', linestyle='-.',label = 'test accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.ylim([0.5, 1])\n","plt.legend(loc='upper left')\n","plt.show()\n","\n","pred = model.predict(X_test)\n","\n","y_pred = np.argmax(pred, axis=1)\n","cm=confusion_matrix(y_pred, y_test)\n","plot_cm(cm)"],"metadata":{"id":"1FobsXYC8RoV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Message:** A clear improvement over the previous network. Possibly some signs of overfitting.\n","\n","**Discussion:** What could be further improvements?"],"metadata":{"id":"SCEgZOsbvuFO"}},{"cell_type":"markdown","source":["## Predictions"],"metadata":{"id":"fvYINrz2L_mx"}},{"cell_type":"markdown","source":["**Task:** Explore some predictions on the test data"],"metadata":{"id":"QyRM8l5g3fsO"}},{"cell_type":"code","source":["idx=4\n","X = X_test[idx]\n","X = np.expand_dims(X, axis=0)\n","\n","pred = model.predict(X)\n","i_max=np.argmax(pred)\n","\n","plt.figure(figsize=(12,6))\n","ax = plt.subplot(2,2,1)\n","plt.imshow(X_test[idx]) \n","\n","ax = plt.subplot(2,2,2)\n","plt.bar(range(10), pred[0])\n","plt.title(class_names[i_max])\n","plt.show()"],"metadata":{"id":"ZjzkyW2dxmT-"},"execution_count":null,"outputs":[]}]}