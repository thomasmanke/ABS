{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOFT79V4v6+B4Fz7Yqn3Hhe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thomasmanke/ABS/blob/main/Notebooks/ANN/ANN_005_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Libraries"
      ],
      "metadata": {
        "id": "_5H1VxaENAex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from httpimport import github_repo\n",
        "with github_repo( 'thomasmanke', 'ABS','ABS_tools') :\n",
        "  import ABS_tools"
      ],
      "metadata": {
        "id": "KyckR-CD0rLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo \"Replaced by module import from github\"\n",
        "# my plot function for confusion matrix\n",
        "def plot_cm(mat):\n",
        "  classes = np.arange(cm.shape[0])\n",
        "  plt.imshow(mat, cmap=plt.cm.Blues)\n",
        "  for (j,i),label in np.ndenumerate(mat):\n",
        "    plt.text(i,j,np.round(label,2),ha='center',va='center')\n",
        "\n",
        "  plt.colorbar()\n",
        "  plt.title('Confusion Matrix')\n",
        "  plt.xlabel('True label')\n",
        "  plt.ylabel('Pred label')\n",
        "  plt.xticks(classes)\n",
        "  plt.yticks(classes)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "rQjL_WywR5JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print('tf-version: ', tf.__version__)"
      ],
      "metadata": {
        "id": "agODGF0KQ282"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenges from previous work (MNIST)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZuqQ0SN81vlR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/smileys.png\",  width=\"500\">\n",
        "</div>\n",
        "\n",
        "- training (and test) data were highly structured: fixed size, grey scale, item centered, only single item \n",
        "\n",
        "**Discussion**: other possible challenges?\n",
        "\n",
        "- spatially distributed features\n",
        "- view point\n",
        "- illumination\n",
        "- deformation\n",
        "- occlusion \n",
        "- intraclass variation\n",
        "\n",
        "Algorithms should be \n",
        "\n",
        "- robuts to those changes within one class (e.g. cat)\n",
        "- generic and transferable to all other classes \n",
        "- interpretable"
      ],
      "metadata": {
        "id": "ahRHyzeDTsv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A short history"
      ],
      "metadata": {
        "id": "ov6w6t23K9RY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algorithms, Compute Power, Data, Data & Data\n",
        "\n",
        "- 1958 Rosenblatt: The perceptron: A probabilistic Model for Information Storage and  Organization in the Brain.\n",
        "- 1998 Le Cun et al.  (MNIST):  60000 images of 10 handwritten digits ($10^7$ pixels) + CPU ($10^6$ transitors)\n",
        "- 2012 Alex Krizhevsky et al (ImageNet): 1.3M images for 1000 classes ($10^{14}$ pixels) + GPU ($10^9$ transistors)\n",
        "- 2021 Yang et al. (MedMNIST): 700k images for 2-11 classes \n",
        "https://github.com/MedMNIST/MedMNIST\n",
        "- 2022 Google Open Images v6: 60M images, 20000 classes: https://storage.googleapis.com/openimages/web/index.html\n",
        "\n"
      ],
      "metadata": {
        "id": "6XgVoYCGx69o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Another classical dataset: CIFAR-10\n",
        "\n",
        "This is a set of 50k images in 10 categories.\n",
        "They are rather coarse (32 x 32), but unlike MNIST and MNIST-Fashion they are not as standardized.\n",
        "\n"
      ],
      "metadata": {
        "id": "RVWuw94zLK49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cell takes 1-2 minutes (on my regular home network)\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "### downsampling to avoid kernel crashes with small RAM (e.g Binder)\n",
        "n_down = 10000\n",
        "n_down_test = int(n_down/5)\n",
        "\n",
        "if (n_down>0):\n",
        "  np.random.seed(42)\n",
        "  print('train-before:', X_train.shape, y_train.shape)\n",
        "  print('test-before: ', X_test.shape, y_test.shape)\n",
        "  id_train = np.random.choice(X_train.shape[0],n_down)\n",
        "  id_test  = np.random.choice(X_test.shape[0],n_down_test)\n",
        "  X_train, y_train = X_train[id_train, ...], y_train[id_train, ...]\n",
        "  X_test, y_test = X_test[id_test, ...], y_test[id_test, ...]\n",
        "  print('train-before:', X_train.shape, y_train.shape)\n",
        "  print('test-before: ', X_test.shape, y_test.shape)\n",
        "\n",
        "# normalization\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "# just for easier reference to replace integers with names\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "SfjAKB6rAq2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Group Task (40 min):  Explore, Model, Fit, Evaluate\n"
      ],
      "metadata": {
        "id": "Q4JXKTI5ngRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore"
      ],
      "metadata": {
        "id": "mhmAI6kQt0Fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo edit before running\n",
        "... Data Exploration ...\n",
        "... shapes etc . ..."
      ],
      "metadata": {
        "id": "yfu1GCoTBVZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Repeat: Try a Simple Neural Network"
      ],
      "metadata": {
        "id": "ocFIL5V5p5ZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "... you might copy the model with one dense layer from the handwritten digits example."
      ],
      "metadata": {
        "id": "cNnlddmDuZiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo define model here\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "eHDHQ3Ewpo0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit"
      ],
      "metadata": {
        "id": "-NSFbxzoL3H7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit model for 20 epochs. Afterwards save the model and the metrics history.\n",
        "\n",
        "RAM limitations? \n",
        "\n",
        "This has been tested on mybinder.org (with 2GB RAM) but if RAM should still be limited you may have to downsample the data further (see above) and/or use smaller batch sizes (16) here."
      ],
      "metadata": {
        "id": "uOn_Ne2xulDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fh = mod1.fit(X_train, y_train, epochs=20, validation_split=0.1, batch_size= 32, verbose=0)\n",
        "\n",
        "model_fn   = 'cifar_model_1.h5'  \n",
        "history_fn = 'cifar_history_1.npy'\n",
        "mod1.save(model_fn)\n",
        "np.save(history_fn, fh) "
      ],
      "metadata": {
        "id": "6gvIneh9qZvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation and Predictions"
      ],
      "metadata": {
        "id": "leUVIpxDLzq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = mod1.evaluate(X_test, y_test)\n",
        "\n",
        "a_name='sparse_categorical_accuracy'\n",
        "val_a_name = 'val_' + a_name\n",
        "plt.plot(fh.history['loss'])\n",
        "plt.plot(fh.history['val_loss'])\n",
        "plt.axhline(y=test_loss, color='green', linestyle='-.',label = 'test')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(fh.history[a_name])\n",
        "plt.plot(fh.history[val_a_name])\n",
        "plt.axhline(y=test_acc, color='green', linestyle='-.',label = 'test')\n",
        "plt.show()\n",
        "\n",
        "mod1_pred = mod1.predict(X_test)           # probabilities    \n",
        "y_pred    = np.argmax(mod1_pred, axis=1)   # classes with max prob (= labels)\n",
        "cm=confusion_matrix(y_pred, y_test)\n",
        "plot_cm(cm)"
      ],
      "metadata": {
        "id": "yhZ9x80oKzxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Message:**\n",
        "\n",
        "There are several ways to improve this (more data, hyperparameters etc.)\n",
        "\n",
        "However, achieving higher (test and valdiation) accuracy on flattened images will generally be difficult $\\to$ change network architecture\n"
      ],
      "metadata": {
        "id": "Wdlp2-2RtkrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks (CNN)\n",
        "... a picture and some jargon"
      ],
      "metadata": {
        "id": "pdNz64M2LZpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![CNN_convlayer](https://upload.wikimedia.org/wikipedia/commons/6/68/Conv_layer.png)\n",
        "(from wikipedia.org)"
      ],
      "metadata": {
        "id": "P27CBX0kuFqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New layers: Filters and Pools"
      ],
      "metadata": {
        "id": "AQ-tk-AUu81J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![filter](https://wiki.tum.de/download/attachments/23572254/cnn6.png)\n",
        "(from wiki.tum.de)"
      ],
      "metadata": {
        "id": "PJm89Rh3vAIy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **input layer:** image shape [width, height, 3 (RGB)]\n",
        "- **convolutional layer** (Conv): n filters e.g (n,3,3,3)\n",
        "\n",
        "  - detect pattern (e.g. horizontal, vertical, diagonal lines)\n",
        "  - have the same depth as input\n",
        "  - several filter per layer: different filters applied to same spatial location in image\n",
        "\n",
        "- **pooling filter** (Pool)\n",
        "  - spatially downsampling, depth stay the same (e.g. max or average)\n",
        "\n",
        "- **fully conncted layer** (Dense)\n",
        "  - connect all previous nodes\n",
        "\n",
        "Typical structures: Input - Conv/Relu - Conv/Relu - Pool - Conv/Relu - ... - Dense\n",
        "\n",
        "Lower layers: Primitive \"concepts\",  Higher layers: Higher order \"concepts\" \n"
      ],
      "metadata": {
        "id": "Wma7ne7z5IDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN: tensorflow implementation"
      ],
      "metadata": {
        "id": "gJ1knw8lLrre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nc = np.unique(y_train).size  # number of classes / labels in training set\n",
        "l_name = 'sparse_categorical_crossentropy'\n",
        "a_name = 'sparse_categorical_accuracy'\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "print('X_train.shape:     ', X_train.shape)\n",
        "print('input_shape:       ', input_shape)\n",
        "print('number of classes: ', nc)\n",
        "\n",
        "model = tf.keras.models.Sequential(name='cifar_CNN_3')\n",
        "\n",
        "# Convolutional layers\n",
        "model.add(tf.keras.layers.InputLayer(input_shape))\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', name='1st_conv'))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# an additional layer\n",
        "#model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', name='2nd_conv'))\n",
        "#model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# as before\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu', name='last'))\n",
        "model.add(tf.keras.layers.Dense(nc, activation='softmax', name='output'))\n",
        "\n",
        "model.compile(optimizer='adam', loss=l_name, metrics=a_name)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "BJ-yuN7WDtIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN: fitting, GPUs and batch size"
      ],
      "metadata": {
        "id": "TMKzfHI_LzH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell will fit the model. This will take some time - especially without dedicated hardware (e.g. GPU) or further optimization (improved algorithm).\n",
        "\n",
        "Alternatively you can obtain the model from the github directory and load it without learning (see instructions below)\n",
        "\n"
      ],
      "metadata": {
        "id": "N7uBGacBNVs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fh = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.1, verbose=0)\n",
        "\n",
        "model_fn   = model.name + '.h5'  \n",
        "history_fn = model.name + '_history.npy'\n",
        "model.save(model_fn)\n",
        "np.save(history_fn, fh)"
      ],
      "metadata": {
        "id": "Q0ESfsnFFwvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Model and History"
      ],
      "metadata": {
        "id": "LYWwtrFayLgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the learning above takes too much time you may also obtain the trained model and metric history from the github data/ directory and load it here."
      ],
      "metadata": {
        "id": "pm_ZeeKswj3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%script echo Run after new start\n",
        "model_fn   = 'cifar_CNN_1.h5'\n",
        "history_fn = 'cifar_CNN_1_history.npy'\n",
        "\n",
        "model = tf.keras.models.load_model(model_fn)\n",
        "fh = np.load(history_fn, allow_pickle=True).item()\n",
        "\n",
        "# For the following to work you also need to load+normalize the test_data !!!!"
      ],
      "metadata": {
        "id": "b8QDf8W1yP9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluations"
      ],
      "metadata": {
        "id": "KWRzo3588PdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo evaluate the model\n",
        "..."
      ],
      "metadata": {
        "id": "RElrWg2TNycC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Message:** An improvement over the previous network.\n",
        "\n",
        "**Discussion:** What could be further improvements?"
      ],
      "metadata": {
        "id": "SCEgZOsbvuFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Task (20 min): Predictions"
      ],
      "metadata": {
        "id": "fvYINrz2L_mx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore individual predictions for test data"
      ],
      "metadata": {
        "id": "QyRM8l5g3fsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo chose an index of your choice\n",
        "idx=...\n",
        "X = X_test[idx]\n",
        "X = np.expand_dims(X, axis=0)\n",
        "\n",
        "pred = model.predict(X)\n",
        "i_max=np.argmax(pred)\n",
        "true_lab=class_names[y_test[idx][0]]\n",
        "pred_lab=class_names[i_max]\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "ax = plt.subplot(2,2,1)\n",
        "plt.imshow(X_test[idx]) \n",
        "plt.title(true_lab)\n",
        "\n",
        "ax = plt.subplot(2,2,2)\n",
        "plt.bar(range(10), pred[0])\n",
        "plt.title(pred_lab)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZjzkyW2dxmT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare all predictions with ground truth for test data"
      ],
      "metadata": {
        "id": "LxOh6sdtxjNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_pred = model.predict(X_test)          # probabilities    \n",
        "y_pred    = np.argmax(model_pred, axis=1)   # classes with max prob (= labels)\n",
        "cm=confusion_matrix(y_pred, y_test)\n",
        "plot_cm(cm)"
      ],
      "metadata": {
        "id": "sX1F7OklxqHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A closer look at layers"
      ],
      "metadata": {
        "id": "zA2058AU9RWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Motivation: Understand prediction in terms of layered \"concepts\""
      ],
      "metadata": {
        "id": "xnxgbqB72Kt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "_s2gmVfvhkx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filters"
      ],
      "metadata": {
        "id": "WpRIpuIoP49d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_name='first_conv'\n",
        "W,b = model.get_layer(layer_name).get_weights()  # by name\n",
        "# W,b = model.layers[0].get_weights()            # by index\n",
        "\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "nr, nc = (2,5)                    # define number of rows and columns\n",
        "for i in range(0, nr*nc):\n",
        "    img = W[:,:,:,i]                                      # each filter has 3D\n",
        "    img = (img - img.min()) / (img.max() - img.min())     # scale -> [0,1]\n",
        "    fig.add_subplot(nr, nc, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title('filter: {}'.format(i))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I6Fou3HMcOpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notice:** Maximal activation for all RGB channels=1 (black) and minimal activation for all RGB channels = 0 (white)"
      ],
      "metadata": {
        "id": "YOhSIofMnZfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The last layer"
      ],
      "metadata": {
        "id": "pNZA70K5Nq88"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of the added convolutional layers is to obtain a better representation of the image data by representing spatial features (edges etc.). If this is successful then we would expect better separation properties in the penultimate layer (last before output layer)."
      ],
      "metadata": {
        "id": "TRPFyCvRNumw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "HGYrtkiV9ABU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# define new model: X -> last layer\n",
        "layer_name = 'last'\n",
        "layer_model = tf.keras.Model(inputs=model.input,\n",
        "                             outputs=model.get_layer(layer_name).output)\n",
        "\n",
        "nr = 1000\n",
        "y=y_train[:nr]\n",
        "X=X_train[:nr]\n",
        "X_lay = layer_model(X).numpy()   # last layer representation of X\n",
        "\n",
        "X = X.reshape(nr,-1)                # flatten each image\n",
        "X_lay = X_lay.reshape(nr,-1)        # flatten each image (redundant)\n",
        "\n",
        "print('X shapes: ',X.shape, X_lay.shape)\n",
        "\n",
        "#X_pca = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(X)\n",
        "#X_lay_pca = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(X_lay)\n",
        "\n",
        "X_pca = PCA(n_components = 2).fit_transform(X)\n",
        "X_lay_pca = PCA(n_components = 2).fit_transform(X_lay)\n",
        "print('PCA Shapes: ',X_pca.shape, X_lay_pca.shape)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "cm = plt.get_cmap('tab10')\n",
        "\n",
        "ax = plt.subplot(1, 2, 1)\n",
        "plt.scatter( X_pca[:,0], X_pca[:,1] , c=y, cmap=cm)\n",
        "plt.title('PCA: X orig.')\n",
        "\n",
        "ax = plt.subplot(1, 2, 2)\n",
        "plt.scatter( X_lay_pca[:,0], X_lay_pca[:,1] , c=y, cmap=cm)\n",
        "plt.title('PCA - X transformed')\n",
        "\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5HrzITiAne2S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}