{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ANN_004_ImageClassification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPt6EgJYXJZdQkIukSNC8pJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Image Classification\n","\n"],"metadata":{"id":"9eJVzsw3ovB_"}},{"cell_type":"markdown","source":["**Goal:** Given many images and their labels, learn a neural network to predict the label of a new image (c.f human learning)."],"metadata":{"id":"fDLvMoIhtYRr"}},{"cell_type":"markdown","source":["**Repetitions:**\n","- Define Model & Optimization Strategy\n","- Fit Model\n","- Monitor Fitting\n","- Evaluate Training \n","\n","**New items:**\n","\n","- Data Splitting: Train & Test\n","- How to handle images: data structure\n","\n","- "],"metadata":{"id":"HsGfslxvhWMF"}},{"cell_type":"markdown","source":["# Get Libraries"],"metadata":{"id":"_5H1VxaENAex"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","print('tf-version: ', tf.__version__)\n","\n","# my plot function for confusion matrix\n","def plot_cm(mat):\n","  classes = np.arange(cm.shape[0])\n","  plt.imshow(mat, cmap=plt.cm.Blues)\n","  for (j,i),label in np.ndenumerate(mat):\n","    plt.text(i,j,np.round(label,2),ha='center',va='center')\n","\n","  plt.colorbar()\n","  plt.title('Confusion Matrix')\n","  plt.xlabel('True label')\n","  plt.ylabel('Pred label')\n","  plt.xticks(classes)\n","  plt.yticks(classes)\n","  plt.show()"],"metadata":{"id":"Q40zhW1fNDoZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Get Data"],"metadata":{"id":"gp6YGTDxLSTC"}},{"cell_type":"markdown","source":["Many famous datasets can be found here:  https://www.tensorflow.org/datasets/catalog/overview\n","\n","They can be accessed easily using keras functionality.\n","\n","In the following we will focus on squared images of handwritten digits. They have also been annotated (labeled)."],"metadata":{"id":"MfdKyjkzNM1l"}},{"cell_type":"code","source":["mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"metadata":{"id":"XBLF1bnLLUxX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Test and Training Sets"],"metadata":{"id":"Vl38XgCSTqtV"}},{"cell_type":"markdown","source":["For models with many parameters there is a real danger of **overfitting**, i.e. learning the specifics of one set of samples rather than generalizable rules.\n","\n","For performance evaluation it is crucial to retain an independent (but representative) **test data set** that it is never used for fitting.  Using keras functionality, we loaded both training data and test data at the same time. If your data does not come split, you may have to do one of the following:"],"metadata":{"id":"niN-HRCe1W0k"}},{"cell_type":"code","source":["%%script echo Suggestions for general (X,y). Do not run here\n","fract = 0.80\n","\n","idx = numpy.random.permutation(X.shape[0]) # shuffle indices\n","s = round(X.shape[0]*fract)                # split point\n","train_idx, test_idx = idx[:s], idx[s:]\n","X_train, X_test = X[train_idx,:], X[test_idx,:]\n","# similar for labels\n","\n","# sklearn\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = fract)\n","\n","# keep in mind that the test data set should be representative\n","# See here for stratified partitioning\n","https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html"],"metadata":{"id":"SC51MsE22s8y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Task (15 min): Data Inspection."],"metadata":{"id":"4OzeFrperTvk"}},{"cell_type":"markdown","source":["- Inspect the types and shapes of the newly defined objects: X_train, y_train, ...\n","- Have a look at the data (array) of the 42nd training image and describe what you see\n","- What is the maximal/minimal number in this image data?\n","- Plot the image using plt.imshow. Use the argument cmap='Greys'\n","- What is the label of this image?"],"metadata":{"id":"sQwoO6heEtdf"}},{"cell_type":"code","source":["%%script echo edit here\n","...\n","..."],"metadata":{"id":"U-l4iwhcEn_R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Normalization"],"metadata":{"id":"RevDcT1gtv6D"}},{"cell_type":"markdown","source":["**Alert:** Usually many more steps are involved in preparing data for analysis:\n","reading, reformating, filtering, shuffeling, transformation, normalization. This can take up a significant amount of time. \n","\n","Here we rely on a highly standardize data set and will only use normalization for illustration. It is important to do so consistently for both training and test data."],"metadata":{"id":"TQZ4lerVLSj5"}},{"cell_type":"code","source":["# Run this code cell only once !!!\n","X_train = X_train / 255.0\n","X_test  = X_test  / 255.0"],"metadata":{"id":"hHIX2rOEty47"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Flattening"],"metadata":{"id":"jItEAEZvq2XI"}},{"cell_type":"markdown","source":["A common procedure to process images is to first \"flatten\" them to a vector. This step will ultimately be done inside the neural network.\n","The line below just illustrates the behaviour for a specific image:"],"metadata":{"id":"DF4unoFdQTi8"}},{"cell_type":"code","source":["print('original:  ', X_train[42,:].shape)\n","print('flattened: ', X_train[42,:].flatten().shape)"],"metadata":{"id":"OvmRU-rXPvWO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dimensional Reduction"],"metadata":{"id":"hhcdiYS6yiC6"}},{"cell_type":"markdown","source":["**Quiz:** What's the dimensionality of an image? (=How many features does one sample have?)\n","\n","There are various ways to project high-dimensional data to lower dimensions  - mostly for data exploration and visualization. Below I use PCA."],"metadata":{"id":"0hAwH6InLkwf"}},{"cell_type":"code","source":["from sklearn.decomposition import PCA\n","\n","ns = X_train.shape[0] # total number of samples\n","nr = 500              # random number of subsamples\n","idx=np.random.choice(ns, nr, replace=False)\n","X_sub = X_train[idx,:].reshape(nr,-1)  # flatten each of the nr images\n","X_pca = PCA(n_components = 2).fit_transform(X_sub)\n","print('Scores: ',X_pca.shape)\n","\n","cm = plt.get_cmap('tab10')\n","plt.scatter( X_pca[:,0], X_pca[:,1] , c=y_train[idx], cmap=cm)\n","plt.title('PCA')\n","plt.colorbar()\n","plt.show()"],"metadata":{"id":"OQUPfZQwEd23"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define and Compile Neural Network Model\n","\n","New Elements\n","- Relu Activation: Rectified Linear Unit (search for simple non-linearity)\n","- Adam Optimizer: don't get stuck in sharp local minima $\\to$ adaptive learning rates (100k citations !)"],"metadata":{"id":"Jzwa-fBVzvVG"}},{"cell_type":"code","source":["nc = np.unique(y_train).size  # number of classes / labels in training set\n","l_name = 'sparse_categorical_crossentropy'\n","a_name = 'sparse_categorical_accuracy'\n","\n","input_shape = X_train.shape[1:]\n","\n","print('X_train.shape:     ', X_train.shape)\n","print('input_shape:       ', input_shape)\n","print('number of classes: ', nc)\n","\n","mod1 = tf.keras.Sequential( name = 'mnist_model_1')\n","mod1.add( tf.keras.layers.Flatten(input_shape=input_shape) )                # flattens input to vector \n","mod1.add( tf.keras.layers.Dense(128, activation='relu',name='1st_layer') )  # add layer with 128 nodes + relu\n","mod1.add( tf.keras.layers.Dense(nc, activation='softmax', name='softmax_layer') )\n","\n","mod1.compile(optimizer='sgd', loss=l_name, metrics=a_name)\n","\n","mod1.summary()"],"metadata":{"id":"tSL6sIocq6AF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Group Tasks (40 min + 10min):"],"metadata":{"id":"vWvZf5r9B52I"}},{"cell_type":"markdown","source":["Now we are ready to go. Repeat the usual steps\n","\n","- Fitting: start with low number of epochs (~10)\n","- Tracking of fit performance (Loss, Accuracy)\n","- Model Evaluation: now you have test data $\\ne$ training data\n","- Predictions: infer labels (np.argmax)\n","- Iterations and improvements (some ideas)\n","  - increase the number of epochs\n","  - increase the number of neurons in dense layer\n","  - add additional layer\n","  - introduce a \"validation_split\" during fitting. Note that this adds additional information to your history that  can be used to control for overfitting.\n","- Reality check: scan your own handwritten digit and submit it to your learned model. Does it work?\n","\n","Summary: Report your summary and preferred solution back to the whole class\n","\n","Tip: If you are on colab.research.google, you might want to activatate the \"GPU hardware accelerator\" under \"Change runtime type\""],"metadata":{"id":"lh-MWh0dqW7_"}},{"cell_type":"markdown","source":["## Fit Model"],"metadata":{"id":"IdcP7vgP0IbE"}},{"cell_type":"code","source":["... "],"metadata":{"id":"t0fKInjCrGFp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"MqOxRqo7PMBm"}},{"cell_type":"markdown","source":["For exploration and debugging purposes it will be better to decouple\n","evaluation from the (long) fitting process. But they belong together."],"metadata":{"id":"cJy-cO7iOt5O"}},{"cell_type":"code","source":["... plot loss and accuracy ...\n","\n","... evaluate on _test_data_ ...\n","\n","... predict on test data ...\n","\n","... convert prediction to labels ... ---> np.argmax()\n","\n","... compare predicted labels with known labels y_test ...\n"],"metadata":{"id":"jyD0jBHGrQ7L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load own image"],"metadata":{"id":"KO5FSSCWP13o"}},{"cell_type":"code","source":["%%script echo Make sure to set proper image path and size (to match the model)\n","from tensorflow.keras.preprocessing import image\n","\n","img_path= ...        # set path\n","input_size=(.., ..)  # chose proper size\n","img = image.load_img(img_path, target_size=input_size) # load image\n","plt.imshow(img)\n","plt.show()"],"metadata":{"id":"GVgfnpdUP3gR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["pass your image to the neural network and predict the label!"],"metadata":{"id":"E1BJFNKOUCTn"}}]}