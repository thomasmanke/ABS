{"cells":[{"cell_type":"markdown","metadata":{"id":"EUS7uJgwbK4o","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["# From last lecture"]},{"cell_type":"markdown","metadata":{"id":"Q5pQh27N4vz6","tags":[]},"source":["Model parameters: $\\Theta=(\\pi,P,E)$ \n","\n","Observations: $X=(X_1, \\ldots X_T)$\n","\n","Hidden States: $Z=(Z_1, \\ldots Z_T)$\n","\n","- most probable path: $argmax_Z Pr(Z|X)$"]},{"cell_type":"markdown","source":["Quiz:\n","\n","1. How many state paths are there for $N=2$ states and sequences of length $T=100$ ?\n","2. Given $P(X,Z)$ how would you calculate $Pr(X)$ ?\n","3. Why would you need $P(X)$?"],"metadata":{"id":"Rzg8WfUzj2ej"}},{"cell_type":"markdown","metadata":{"id":"I5UbfOn3T1RA","tags":[]},"source":["# $P(X)$: The Forward Algorithm"]},{"cell_type":"markdown","source":["(See Notebook: HMM_001_Forward.ipynb for more details)"],"metadata":{"id":"60kuHfi-v3B_"}},{"cell_type":"markdown","source":["## Goal: avoid redundant calculations"],"metadata":{"id":"TFbSBsanpRni"}},{"cell_type":"markdown","source":["... use the power of recursion (\"dynamic programming\")\n","\n","$$P(X) = \\sum_Z P(X_{1:T},Z_{1:T}) \\to \\sum_i P(X_{1:T},Z_T=i)$$\n","\n","... if $P(X_{1:{t+1}},Z_{t+1})$ can be derived from $P(X_{1:{t}},Z_{t})$"],"metadata":{"id":"pZSE-cRdnU3X"}},{"cell_type":"markdown","metadata":{"tags":[],"id":"nC3caTSBlEHT"},"source":["## Idea: track all possibilities"]},{"cell_type":"markdown","metadata":{"id":"Dx1Ny7tQcr_y"},"source":["We don't know any $Z_t$ $\\longrightarrow$ Trellis graph.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1PutwYFAZDaf"},"source":["<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/HMM_HiddenTrellis.jpg\",  width=\"1000\">\n","</div>\n","\n","- Store $\\alpha_{ti} = Pr(X_{1:t}, Z_t=i)$ for each pvalue of $i$ (as $Z_t$ is unobsorved). This vector will be propagated forward in time.\n","\n","- In our previous example we only had 2 states, but the graphic below is an illustration with 4 hidden states\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"tags":[],"id":"zICuZe5nlEHT"},"source":["## Graphical Summary:  2 Steps"]},{"cell_type":"markdown","metadata":{"id":"BO4gayKdSbF2","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/HMM_Forward.jpg\",  width=\"800\">\n","</div>\n","\n","\n","<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/HMM_Forward_summary.jpg\",  width=\"800\">\n","</div>\n","\n","- The Markov Model pushes the state $Z$ forward in time $\\longrightarrow$ *matrix multiplication* with $P$\n","- Emission probabilities: take into account the state-specifc probabilities for observation $X_t$ $\\longrightarrow$ *element-wise multiplication* with proper column of $E$\n"]},{"cell_type":"markdown","metadata":{"id":"yA-z4Jg2i_Hz","tags":[]},"source":["## Notice\n","- **Marginalization:** $Pr(X_{1:t}) = \\sum_i Pr(X_{1:t}, Z_t = i) = \\sum_i \\alpha_{ti}$.  \n","- **Recursion Efficiency:** Calculation of $Pr(X)$ requires $T N^2$ calculations $\\ll N^T$ \n","    - Example: $(N,T) = (2, 100) \\longrightarrow 400 \\ll 2^{100}$  \n","- **Emission matrix** $E_{ik}$ serves as lookup table for given observation $X_t=k$ at time $t$. ($k=f(t)$)"]},{"cell_type":"markdown","metadata":{"id":"_BSfxE-iT1Zb"},"source":["## A single step forward"]},{"cell_type":"markdown","source":["Starting for a given $\\alpha_{ti}$ th code below illustrates a single update in time. All subsequent times follow the same update, but the observed value of $x_t$ will geenerally change from time to time"],"metadata":{"id":"Qk8nBOi-vCHD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7VxyLBGnUH82","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664144308931,"user_tz":-120,"elapsed":252,"user":{"displayName":"Thomas Manke","userId":"17591636328965298454"}},"outputId":"a62e4f3c-c6bc-4a9c-f4e0-dfb0c0f70c48"},"outputs":[{"output_type":"stream","name":"stdout","text":["after state transition:  [0.625 0.375]\n","emission vector:         [0.2 0.1]\n","new probability          [0.125  0.0375]\n"]}],"source":["import numpy as np\n","pi=np.array( [0.75, 0.25] )                          # initial state probability\n","P =np.array([ [0.8, 0.2], [0.1, 0.9] ])              # transition probabilites\n","E =np.array([ [0.7, 0.2, 0.1], [0.1, 0.1, 0.8] ])    # emission probabilties\n","\n","alpha = np.array([0.75, 0.25])  # P(Z_t-1=i|X_t-1):  initial probability at time t-1\n","xt = 1                          # given observation at time t (e.g. 1)\n"," \n","alpha = alpha.dot(P)            # P(Z_t=i | X_t-1):  push Z from t-1 --> t (state transition)\n","print('after state transition: ', alpha) \n","\n","ep=E[:,xt]                      # P(X_t=xt|Z_t=i):  emission probabilities of for each state\n","print('emission vector:        ', LH)\n","\n","alpha = ep * alpha              # P(Z_t=i | X_1:t): posterior  (take into account new observation X_t)\n","print('new probability         ', alpha) "]},{"cell_type":"markdown","source":["## Extensions"],"metadata":{"id":"6CsnsZRl1Fzs"}},{"cell_type":"markdown","source":["- Above we propagated $Pr(X_{1:t}, Z_t=i)$ forward in time, but this works similarly for $Pr(Z_t=i| X_{1:t})$ (plus extra normaliztion)\n","- Forward-backward algortihm for another interesting quantity:  $Pr(Z_t=i| X_{1:T})$\n"],"metadata":{"id":"p0EeNASCxt7P"}},{"cell_type":"markdown","metadata":{"id":"0UQaEHSKwJcn"},"source":["<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/HMM_ForwardBackward.jpg\",  width=\"1200\">\n","</div>\n","\n","$$\n","Pr(Z_t = i | X_{1:T}) = \\gamma_{ti} = \\frac{\\alpha_{ti} \\beta_{ti}}{\\sum_k \\alpha_{tk} \\beta_{tk}} \n","$$\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4vX9p0TKV5dH"},"source":["# The good news: There is software"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4837,"status":"ok","timestamp":1664146107975,"user":{"displayName":"Thomas Manke","userId":"17591636328965298454"},"user_tz":-120},"id":"vujmTrALZdQD","outputId":"448c4ee0-bd4d-47ad-959f-2266124406fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hmmlearn\n","  Downloading hmmlearn-0.2.7-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (129 kB)\n","\u001b[K     |████████████████████████████████| 129 kB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.7/dist-packages (from hmmlearn) (1.0.2)\n","Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from hmmlearn) (1.21.6)\n","Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from hmmlearn) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16->hmmlearn) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16->hmmlearn) (3.1.0)\n","Installing collected packages: hmmlearn\n","Successfully installed hmmlearn-0.2.7\n"]}],"source":["#%%script echo install only once\n","!pip install hmmlearn"]},{"cell_type":"markdown","metadata":{"id":"Wun9E8qPZYd-"},"source":["## HMMlearn: Generating Sequences and Observations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CfZCAgZRZr6h"},"outputs":[],"source":["from hmmlearn import hmm\n","\n","pi=np.array( [0.75, 0.25] )                          # initial state probability\n","P =np.array([ [0.8, 0.2], [0.1, 0.9] ])              # transition probabilites\n","E =np.array([ [0.7, 0.2, 0.1], [0.1, 0.1, 0.8] ])    # emission probabilties\n","\n","np.random.seed(42)                       # only for reproducibiltiy\n","\n","# define HMM and set parameters\n","model = hmm.MultinomialHMM(n_components=2)\n","model.startprob_ = pi                    # initial state prob\n","model.transmat_  = P                     # transition prob\n","model.emissionprob_ = E                  # emission prob\n","\n","# generate sequence\n","X,Z = model.sample(50)                 # c.f. Z, X = generate_HMM(P,pi,E)\n","print('states Z       =',*Z.flatten()) # Z.shape = (T,)\n","print('observations X =',*X.flatten()) # X.shape = (T,1)"]},{"cell_type":"markdown","metadata":{"id":"e_-ZrBAZ08wp"},"source":["# Group Task (30 min): HMM Generation"]},{"cell_type":"markdown","metadata":{"id":"zhG8u7wX1BjT"},"source":["1. Make up your own hidden Markov story, draw the corresponding state graph, and define the Hidden Markov Model. \n","  - Please keep it simple; less than 5 hidden states and less than 5 possible observations. \n","  - Also make sure that the Markov Model for the hidden states is *ergodic* (what was that?)\n","\n","2. Choose your own emission probabilties, transition probabilties and the initital state distribution - make sure they correspond to probabilties. \n","\n","3. Simulate $T=1000$ steps.\n","\n","4. Record (only) the sequence of observations that were generated and store the results as string in a text file (for latter use). Be kind and use integer encoding of observations, i.e. $0,1,\\ldots$ regardless of the interpretation.\n","\n","5. Share your story, code, results and report back to the class."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DaVQuGjh6Yey","tags":[]},"outputs":[],"source":["%%script echo edit before execution (only one per group)\n","\n","model = hmm.MultinomialHMM( ... )\n","model.startprob_ = ...                   # initial state prob\n","model.transmat_  = ...                     # transition prob\n","model.emissionprob_ = ...                  # emission prob\n","\n","T=1000\n","X,Z = ... sample observations and hidden states from model\n","\n","fn='obs_group1.txt'           # choose a group-specific filename\n","\n","### no need to edit below ####\n","\n","# write ######\n","with open(fn, 'w') as f:\n","  m = map(str, X.flatten())   # flatten array and convert numbers to strings\n","  f.write(' '.join(list(m))) \n","\n","# read (for later) ######\n","with open(fn, \"r\") as f:\n","  line  = f.readline().split()  # read first line and split\n","\n","Xr = list(map(np.int64, line))   # map line to np.int64\n","Xr = np.array(Xr).reshape(-1,1)  # return desired shape (T, 1)\n","\n","#print('X =',*X[:10])\n","#print('Xr=',*Xr[:10])\n","np.all(X==Xr)"]},{"cell_type":"markdown","source":["... continue withh HMM_002_Viterbi (Section HMMlearn)"],"metadata":{"id":"Il_M5fq1Axp8"}}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"toc-showcode":false,"toc-showtags":false},"nbformat":4,"nbformat_minor":0}