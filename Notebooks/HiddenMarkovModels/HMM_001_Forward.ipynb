{"cells":[{"cell_type":"markdown","metadata":{"id":"EUS7uJgwbK4o","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["# Typical Problems"]},{"cell_type":"markdown","metadata":{"id":"Q5pQh27N4vz6","tags":[]},"source":["Model parameters: $\\Theta$, Observations: $X$, Hidden States: $Z$\n","\n","- scoring (observations): $Pr(X) \\longrightarrow$ **Forward Algorithm**\n","\n","- decoding (hidden variables):\n","    - best posterior state: $argmax_i Pr(Z_t=i|X) \\longrightarrow$  **Forward-Backward Algorithm**\n","    - best state sequence: $argmax_Z Pr(Z|X) \\longrightarrow$ **Viterbi Algorithm**\n","    \n","- learning (model parameters)  $argmax_\\Theta Pr(\\Theta|X) \\longrightarrow$ **Baum-Welch Algorithm**"]},{"cell_type":"markdown","metadata":{"id":"0mM0HRdYWLEJ","tags":[]},"source":["# Probability of Observations: $Pr(X)$"]},{"cell_type":"markdown","metadata":{"id":"12MOiyxIX5vd","tags":[]},"source":["### Uses: Evaluate (score) observations. \n","\n","Compare different models: \n","$$\n","P(X|\\Theta_1) ~~\\mbox{vs}~~ P(X|\\Theta_2)\n","$$"]},{"cell_type":"markdown","metadata":{"id":"b0o6LekPECm-","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["### First idea: Chain rule\n","$$\n","P(X) = P(X_1) P(X_1|X_2) P(X_3|X_1,X_2) \\ldots P(X_T| X_1, \\ldots ,X_{T-1})\n","$$\n","\n","... not calcuable from HMM parameters"]},{"cell_type":"markdown","metadata":{"id":"XUYRpDW7DR9U"},"source":["### Second idea: Naive Marginalization\n","\n","Use joint distribution $Pr(X,Z)$ and remove hidden state sequence (it is unobservable) $\\to$ marginalize\n","\n","$$\n","Pr(X) = \\sum_Z P(X,Z) = \\sum_Z Pr(X|Z) Pr(Z)\n","$$"]},{"cell_type":"markdown","metadata":{"id":"XMIigFgFX34E"},"source":["### Notice\n","- remember: each term in sum breaks into emission probabilities, transition probabilities (and initial state probability)\n","- marginalization over *all possible* state paths $Z$ ($=Z_{1:T} = Z_1, Z_2, \\cdots Z_T$) \n","- $N^T$ paths for $N$ possible states and sequences of length $T \\longrightarrow $  unfeasible"]},{"cell_type":"markdown","metadata":{"id":"3FUsE_8LWXfb","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["## Third idea: Dynamic Programming (reuse previous calculations)"]},{"cell_type":"markdown","metadata":{"id":"I5UbfOn3T1RA","tags":[]},"source":["# The Forward Algorithm"]},{"cell_type":"markdown","metadata":{"tags":[],"id":"nC3caTSBlEHT"},"source":["## Idea and Visalization"]},{"cell_type":"markdown","metadata":{"id":"Dx1Ny7tQcr_y"},"source":["We don't know any $Z_t$, so we need to **track all possibilities**: $\\longrightarrow$ Trellis graph."]},{"cell_type":"markdown","metadata":{"id":"1PutwYFAZDaf"},"source":["<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/HMM_HiddenTrellis.jpg\",  width=\"1000\">\n","</div>\n","\n","**Recursion** again !!!\n","\n","Let's assume that at some time $t$ we already know the joint probability for the observed sequence $X_{1:t}$ and the hidden state $Z_t$ (for each possible value of $Z_t=i$).\n","\n","This information is stored in the **forward variable:** $\\alpha_{ti} = Pr(X_{1:t}, Z_t=i)$. This is a vector of joint probabilities that will be propagated forward in time.\n","\n","This works efficiently because of the Markov property (separation of future from past, given the present).\n","\n"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"IPAutNRIlEHT"},"source":["## Algorithmic Formulation: Iteration"]},{"cell_type":"markdown","metadata":{"id":"h6Vlsnm3a7q-","tags":[]},"source":["### 1. Initialization ($t=1$) \n","$$\n","\\alpha_{1i} = Pr(X_1, Z_1=i) = Pr(X_1|Z_1=i) Pr(Z_1=i)\n","$$\n","  - \n","   $\\to$ element-wise multiplication of a row from emission matrix with initial state distributions\n","  - $Pr(X_1|Z_1=i)$ is one element of the emission matrix $E_{ik}$ (row i = state, column k = k(1) observed valuee of $X_1$). \n","  - $Pr(Z_1=i)$ is the i-th element of the initial state distribution $\\pi_i$.\n","\n","\n","\n","### 2. Induction ($t \\to t+1$): state transition + new observation \n","  - *2.1 state transition ($Z_t \\to Z_{t+1}$):* Consider all possible Markov transitions and sum them up.\n","$$\n","\\begin{align}\n","Pr(Z_{t+1}=i, X_{1:t}) &= \\sum_k Pr(Z_{t+1}=i, Z_t=k, X_{1:t}) \\\\\n","&=\\sum_k Pr(Z_{t+1}=i|Z_t=k, X_{1:t}) Pr(Z_t=k,X_{1:t}) \\\\\n"," &= \\sum_{k} P_{ki} \\alpha_{tk}  = \\sum_{k} \\alpha_{tk} P_{ki}\n","\\end{align}\n","$$\n","$\\to$ matrix multiplcation of row vector $\\alpha_{tk}$ with transition matrix\n","  - *2.2 new observation ($X_{t+1}$):* consider emission probability resulting in observation $X_{t+1}$\n","$$\n","Pr(Z_{t+1}=i, X_{1:t}, X_{t+1}) = Pr(X_{t+1}|Z_{t+1}=i) Pr(Z_{t+1}=i, X_{1:t})\n","$$\n","$\\to$ element-wise multiplication of a row from emission matrix with \n","\n","\n","\n","### 3. Termination ($T=T$): Marginalization\n","$$\n","Pr(X) = Pr(X_{1:T}) = \\sum_i Pr(X_{1:T}, Z_T=i) = \\sum_i \\alpha_{Ti}\n","$$"]},{"cell_type":"markdown","metadata":{"tags":[],"id":"zICuZe5nlEHT"},"source":["## Graphical Summary:  2 Steps"]},{"cell_type":"markdown","metadata":{"id":"BO4gayKdSbF2","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/HMM_Forward.jpg\",  width=\"800\">\n","</div>\n","\n","\n","<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/HMM_Forward_summary.jpg\",  width=\"800\">\n","</div>\n","\n","- The Markov Model pushes the state $Z$ forward in time $\\longrightarrow$ matrix multiplication with $P$\n","- Emission probabilities: take into account the state-specifc (time-dependent) probabilities for observation $X_{t+1}$ $\\longrightarrow$ element-wise multiplication with proper column of $E$\n"]},{"cell_type":"markdown","metadata":{"id":"yA-z4Jg2i_Hz","tags":[]},"source":["## Notice\n","- **Marginalization:** $Pr(X_{1:t}) = \\sum_i Pr(X_{1:t}, Z_t = i) = \\sum_i \\alpha_{ti} \\ne 1$.  In fact, it is much smaller than 1 for large $t$ !\n","- **Recursion Efficiency:** Forward Propagation of $\\alpha_{tk}$ **is fast** (linear in sequence length $T$)\n","    - Calculation of $Pr(X)$ requires $T N^2$ calculations $\\ll N^T$ \n","    - Example: $(N,T) = (2, 100) \\longrightarrow 400 \\ll 2^{100}$  \n","- **Emission matrix** $E_{ik}$ serves as lookup table for given observation $X_t=k$ at time $t$. ($k=f(t)$)"]},{"cell_type":"markdown","metadata":{"id":"_BSfxE-iT1Zb"},"source":["## Group Task (30 min): A single step forward in time"]},{"cell_type":"markdown","source":["$$Pr(Z_{t-1}=i, X_{1:t-1}) \\to Pr(Z_t=i, X_{1:t})$$"],"metadata":{"id":"9Wc_eHdVdpak"}},{"cell_type":"markdown","metadata":{"id":"XvwDurm2UH82"},"source":["Given the above HMM  with 2 states (Germany=0, Switzerland=1) and a magically known joint probability $Pr(Z_{t-1}, X_{1:t-1})=(0.05, 0.02)$. I made those numbers up, and it is irrelevant which history of observations resulted in these probabilities. They denotes the probability for the two states **and** all observations until time $t-1$. Notice that this does not have to sum to 1! But (thanks to Markov) this is all you need to calculate the next step.\n","\n","Calculate the updated probability for $Z_t=$ Germany (0) **and** that the new observation $X_t$ is Bread (0), Fish (1) or Fondue (2). \n","\n","- Group 1: $P(Z_t=0, X_{1:t-1}, X_t=0) = $ ? \n","- Group 2: $P(Z_t=0, X_{1:t-1}, X_t=1) = $ ?\n","- Group 3: $P(Z_t=0, X_{1:t-1}, X_t=2) = $ ?"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"7VxyLBGnUH82","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655163397656,"user_tz":-120,"elapsed":194,"user":{"displayName":"Thomas Manke","userId":"17591636328965298454"}},"outputId":"834866d3-6daa-4bbf-fc6d-f4e056a3e6a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["after state transition:  [0.042 0.028]\n","emission vector:         [0.7 0.1]\n","new probability          [0.0294 0.0028]\n","posterior norm: [0.91304348 0.08695652]\n"]}],"source":["import numpy as np\n","pi=np.array( [0.75, 0.25] )                          # initial state probability\n","P =np.array([ [0.8, 0.2], [0.1, 0.9] ])              # transition probabilites\n","E =np.array([ [0.7, 0.2, 0.1], [0.1, 0.1, 0.8] ])    # emission probabilities\n","\n","alpha = np.array([0.05, 0.02])  # initial probability at time t-1  (prior)\n","xt = 0                          # observation of interest at time t. (Bread = 0)\n","\n","alpha = alpha.dot(P)            # push prior with P from t-1 --> t (state transition)\n","print('after state transition: ', alpha) \n","\n","LH=E[:,xt]                      # pick emission probs for observation xt\n","print('emission vector:        ', LH)\n","\n","alpha = LH * alpha              # elementwise multiplication pf alpha with LH\n","print('new probability         ', alpha)   # \n","\n","# only for calculation of conditional probability\n","#alpha /= np.sum(alpha)          # normalized posterior\n","#print('posterior norm:', alpha)"]},{"cell_type":"markdown","metadata":{"id":"olcqbIellEHV"},"source":["## Remarks"]},{"cell_type":"markdown","metadata":{"id":"HrR31S0CTEuK","tags":[]},"source":["- *Monitoring*: With the same recipe we can progagate the **conditional probability distribution**\n","$$Pr(Z_{t-1}=i| X_{1:t-1}) \\to Pr(Z_t=i | X_{1:t})$$\n","through time - rather than the joint $Pr(Z_t=i, X_{1:t})$.\n","-  We simply have to normalize after every time step.\n","$$Pr(Z_t=i|X_{1:t}) = Pr(Z_t=i,X_{1:t})~/~Pr(X_{1:t})$$ \n"]}],"metadata":{"colab":{"collapsed_sections":["EUS7uJgwbK4o","0mM0HRdYWLEJ","12MOiyxIX5vd","b0o6LekPECm-","XUYRpDW7DR9U","XMIigFgFX34E","3FUsE_8LWXfb","nC3caTSBlEHT","IPAutNRIlEHT","h6Vlsnm3a7q-","zICuZe5nlEHT","yA-z4Jg2i_Hz"],"name":"HMM_001_Forward.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"toc-showcode":false,"toc-showtags":false},"nbformat":4,"nbformat_minor":0}