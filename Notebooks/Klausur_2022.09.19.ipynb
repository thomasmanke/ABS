{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Klausur_2022.09.19.ipynb","provenance":[],"collapsed_sections":["TAnJASH5quJk","KmquoP14rDqe","tdAPA9VJIv_H","V94CnEE8I3B0","O2nv6ZX4NWT4","2tyg07p1vHdY","rlCQxCEjTHth","-Eaw4p1vTEeF","sJDkDz68Q5zM","IB8Urui41lRB","AwZkXQtP1-KN","yOh4_l0m2XTS","SfiQP2r4zeuz"],"authorship_tag":"ABX9TyNcZKCnPHs3ruhj1auVkcVI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# General Remarks"],"metadata":{"id":"x_76Q3SFJOYW"}},{"cell_type":"markdown","source":["- Please complete all tasks (text and code) directly in this notebook\n","- Save the notebook with your first name and surname in the filename:  e.g. **Klausur_ThomasManke.ipynb**\n","- Submit as github repo (preferred), alternatively you can upload the notebook to the CQ portal (and share with me)\n","- This test will cover three parts: Markov chains, Hidden Markov Models, Artifical Neural Networks\n","- Each part will need their own and sometimes overlapping packages to import (e.g numpy). Even if it is redundant, import the relevant parts explicitly at the beginnig of each part.\n","- Complete the code cells in their respective sections and add (concise) text, where more verbal explanations are required. Comments in the code cells are also welcome.\n","- Feel free to add multiple code cells if you prefer, but make sure that they stay in their respective sections\n","- All tasks have been tested with mybinder.org and should run on any modern laptops (with 2 GB free RAM).\n","Make sure to switch off other resource hungry programs.\n","If you encounter any technical problems, please inform me immediately !\n","- Deadline for submission: **21.06. 2022 15:30**\n","\n","\n","---\n","\n"],"metadata":{"id":"rkRkOLhWdTTq"}},{"cell_type":"markdown","source":["# Markov Chains"],"metadata":{"id":"TAnJASH5quJk"}},{"cell_type":"markdown","source":["##  The story: A ball game"],"metadata":{"id":"KmquoP14rDqe"}},{"cell_type":"markdown","source":["Alice, Bob and young Clemens are playing a new ball game - here are the rules:\n","- If Alice has the ball, she will throw a (fair 6-sided) die and keep the ball if she throws a 6, otherwise she'll pass the ball to Bob\n","- If Bob has the ball, he'll pass it to Alice or Clemens, based on the throw of a fair coin\n","- If Clemens has the ball he'll return it to the child from whom he got it \n","\n","At the beginning of the game, their father throws the ball to Alice or Bob.\n","However, he is three times more likely to throw it to Alice, and he never throws it to Clemens."],"metadata":{"id":"EKy4tTaCIquy"}},{"cell_type":"markdown","source":["## The Tasks"],"metadata":{"id":"tdAPA9VJIv_H"}},{"cell_type":"markdown","source":["Translate the story into a Markov Model. \n","Optionally: add a scanned drawing of the Markov graph as jpeg file to this notebook.\n","\n","- What are the states and how many states are there?\n","- What is the initial state distribution ? Write it down as numpy.array below.\n","- Write down the transition matrix as numpy.array.\n","- Does the Markov Model have a stationary distribution - and does your answer depend on whether Alice has a fair die? \n","- Validate your answer numerically with the \"matrix power method\". \n","- For each child, give their long-term probabilities that they hold the ball. \n","- Bonus: In the fair die scenario, what is the number of steps that Alice can expect to hold the ball before having to pass it on. "],"metadata":{"id":"kDyilCfuBA1C"}},{"cell_type":"markdown","source":["## Your solutions"],"metadata":{"id":"V94CnEE8I3B0"}},{"cell_type":"code","source":["# import the necessary modules\n","\n","\n","print('long-term probabilities:    ', ...)\n","print('expected stretch for Alice: ', ...)"],"metadata":{"id":"qBMuoo06-ZCV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Your verbal answers here:"],"metadata":{"id":"MNqxwSCebwtR"}},{"cell_type":"markdown","source":["# Hidden Markov Models"],"metadata":{"id":"nu1MafVSBSl3"}},{"cell_type":"markdown","source":["## A story"],"metadata":{"id":"FQm0LsInNOw-"}},{"cell_type":"markdown","source":["The DNA of a (hypothetical) organism exists in 3 different configurations (0,1,2) that cannot be observed directly. They are, however, characterized by a specific distribution of observable nucleotides (A,C,G,T) that are emitted from each state. The state transition rates and emission rates are shown in the figure below.\n","<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/HMM_DNA.jpg\",  width=\"1000\">\n","</div>\n","\n","\n","This problem can be modelled as a hidden Markov Model.\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"7po_s2CvswW0"}},{"cell_type":"markdown","source":["## Tasks"],"metadata":{"id":"jEe2gQXau2ZM"}},{"cell_type":"markdown","source":["1. Write down the HMM parameters as numpy arrays. The initial state probability $\\pi$ is not given, but you may assume that it is the stationary distribution of state transitions - calculate it and report it.\n","\n","2. Using MultinomialHMM() from the hmmlearn package, set up a probabilistic model with the parameters $(\\pi, P, E)$.\n","\n","3.  Sample a sequence of 2000 hidden states $Z$ and the corresponding observations $X$ from the model. Use a random seed = 42 for reproducibility.\n","Report the first 20 pairs of hidden states and observations.\n","\n","\n","4. Calculate the logarithm of the probability $\\log Pr(X)$ given the model from which you generated $X$ - why is it so low (1-2 sentences)?\n","\n","5. Name two algorithms to decode the \"best\" possible path of hidden states $Z$ from observations $X$ and a given model. Briefly describe their different goals (2 sentences).\n","Run the respective function from hmmlearn to calculate \n","$Z$ for both methods, given the $X$ and the current model.\n","Save the result as $Z_1$ and $Z_2$.\n","Report the number of differences between $Z_1$ and $Z_2$.\n","\n","6. Use the hmmlearn implementation of the Baum-Welch algorithm to determine the best parameters for the HMM model, if only $X$ is given. \n","  - You will have to define a new model that does not yet know any parameters (e.g. model_fit). \n","  - You may assume that the number of hidden states is known to be 3.\n","  - Set \"np.random.seed(1)\" and run 500 iterations. \n","  - Compare the results with your knowlegde of parameters from the generating model for $X$. You might want to round the fitted parameters to two digits: np.round(...,2)\n","  - Comment on possible difference and name two ways in which you might improve the parameter fit."],"metadata":{"id":"xKdsvIW3u_2Q"}},{"cell_type":"markdown","source":["## Load the Software"],"metadata":{"id":"O2nv6ZX4NWT4"}},{"cell_type":"code","source":["# install hmmlearn (if necessary)\n","!pip install hmmlearn"],"metadata":{"id":"DOJ7Jf5n4jp_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import modules you need\n","\n"],"metadata":{"id":"JSndHuWEIvWx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Your solution"],"metadata":{"id":"Gv-tnbcgNtCQ"}},{"cell_type":"code","source":["P = np.array(...) # transitions\n","E = np.array(...) # emission\n","pi= ....          # statitonary distribution\n","\n","# define model\n","...\n","\n","# sample from model\n","...\n","\n","print('Z=', *Z[:20])\n","print('X=', *X.flatten()[:20])\n","\n","# log P(X)\n","print('log P(X) = ', )\n","\n","# two ways to predict best path\n","... Z1 ...\n","... Z2 ...\n","\n","# differences between two paths Z1 and Z2\n","\n","\n","# new model for fit\n","...\n","\n","# print results\n","print('fit score:    ', ... )\n","\n","print('fitted P: \\n', np.round(...,2))\n","print('known P: \\n', P)\n","print('\\n')\n","print('fitted E: \\n'  , np.round(...,2))\n","print('know E: \\n', E)\n"],"metadata":{"id":"8B-9ZpE8I3HH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Artificial Neural Networks\n","\n","\n"],"metadata":{"id":"wFxYP6rw4kUp"}},{"cell_type":"markdown","source":["## The Data"],"metadata":{"id":"2tyg07p1vHdY"}},{"cell_type":"markdown","source":["The MINST-Fashion dataset contains a large number of (small and coarse-grained) images from fashion items. This set has been annotated with labels for both traing and test data sets.\n","\n","Link: https://www.tensorflow.org/datasets/catalog/fashion_mnist\n","\n","The goals is to construct a Neural Network that can predict the fashion label from a given image.\n","\n","The sections below will describe the individual tasks."],"metadata":{"id":"Flb0KZGWvNK5"}},{"cell_type":"markdown","source":["## Load Packages"],"metadata":{"id":"rlCQxCEjTHth"}},{"cell_type":"code","source":["# import required packages\n","\n","# a convenience function\n","def plot_cm(mat):\n","  classes = np.arange(cm.shape[0])\n","  plt.imshow(mat, cmap=plt.cm.Blues)\n","  for (j,i),label in np.ndenumerate(mat):\n","    plt.text(i,j,np.round(label,2),ha='center',va='center')\n","\n","  plt.colorbar()\n","  plt.title('Confusion Matrix')\n","  plt.xlabel('True label')\n","  plt.ylabel('Pred label')\n","  plt.xticks(classes)\n","  plt.yticks(classes)\n","  plt.show()"],"metadata":{"id":"VSvmyi-WS8Dw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load Data"],"metadata":{"id":"-Eaw4p1vTEeF"}},{"cell_type":"markdown","source":["This section is given purposefully. Simply run it to get train and test data together with the respective labels. \n","\n","Also keep the normalization as is."],"metadata":{"id":"3L-_ELx9-uBh"}},{"cell_type":"code","source":["mnist = tf.keras.datasets.fashion_mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# normalization\n","X_train, X_test = X_train / 255.0, X_test / 255.0"],"metadata":{"id":"CdZXakVXBU94"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Exploration and Preprocessing"],"metadata":{"id":"sJDkDz68Q5zM"}},{"cell_type":"markdown","source":["- How many images (=samples) are included in the training data? \n","- What is the shape of these images?\n","- How many distinct labels does it have? "],"metadata":{"id":"es5baF90Q-iv"}},{"cell_type":"code","source":[""],"metadata":{"id":"5hfheoJlRNEd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define Model and Learning Strategy"],"metadata":{"id":"IB8Urui41lRB"}},{"cell_type":"markdown","source":["Construct an artifical neural network with\n","\n","- an input layer that takes the proper shape of images\n","- a dense layer with 128 nodes including a 'ReLu' activation function for non-linear mapping \n","- an output layer corresponding to the number of classes in the problem and a softmax activation function\n","\n","Use the Adam optimizer and define a suitable loss function.\n","Make sure that during the learning process you will track both loss and 'sparse_categorical_accuracy' as metrics.\n","\n","Summarize the model. How many parameters does it have?"],"metadata":{"id":"DT1r9bfm15DE"}},{"cell_type":"code","source":["# Define Model and Learning strategy here\n","\n","\n","..."],"metadata":{"id":"M38ECS3h1j8P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fit the Model"],"metadata":{"id":"AwZkXQtP1-KN"}},{"cell_type":"markdown","source":["Fit the model to the training data for 10 epochs - \n","use 10% of the ttraining data for validation.\n","\n","Once the fit is finished you may save the model."],"metadata":{"id":"M6M6rQrPSgQj"}},{"cell_type":"code","source":["...."],"metadata":{"id":"YB-KM86B2AyG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluate the Model"],"metadata":{"id":"yOh4_l0m2XTS"}},{"cell_type":"markdown","source":["Plot the history of loss and accuracy for the training and validation set and compare it the same metrics obtained (after fitting) for the test data.\n","\n","Are there any indications for overfitting - explain this briefly (1-2 sentences)."],"metadata":{"id":"iRUzrhTbTXVQ"}},{"cell_type":"code","source":["# Evaluation & Learning history\n","\n","...\n",".."],"metadata":{"id":"Tj2kOkt12bMB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Inspect predictions"],"metadata":{"id":"62Hi3nvoycq4"}},{"cell_type":"markdown","source":["Inspect the test image with index 43 and compare the predicted label with the true label.\n","\n","Compare all predicted label from the test set with all true labels - you may want to use the plot_cm() funcion defined above."],"metadata":{"id":"C3H-rByvyk6l"}},{"cell_type":"code","source":["id=43\n","\n","... prediction and inspection for one test image\n","\n","\n","... predictions for all test images\n","\n","... obtain confusion matrix ...\n"],"metadata":{"id":"HVGkIBJEbYdf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Suggestions for improvements"],"metadata":{"id":"SfiQP2r4zeuz"}},{"cell_type":"markdown","source":["Make suggestions for possible improvements to the model and the fitting process\n","\n","- \n","-\n","-\n"],"metadata":{"id":"tJc4f4eSzjRL"}}]}