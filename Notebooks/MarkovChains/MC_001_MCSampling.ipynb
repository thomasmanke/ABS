{"cells":[{"cell_type":"markdown","metadata":{"id":"FkekGi6um5xh"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/thomasmanke/ABS/blob/main/Notebooks/MarkovChains/MC_001_MCSampling.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"E1DFkwtNry9v"},"source":["# Markov Chain Sampling"]},{"cell_type":"markdown","metadata":{"id":"9AxEWXawELse"},"source":["## Background "]},{"cell_type":"markdown","metadata":{"id":"Y3ejd9auHyQT"},"source":["In the models discussed previously, all observations were sampled independently of each other, and from the same distribution (*iid*): \n","\n","$$X \\propto N(\\mu, \\sigma^2)$$\n","\n","In higher dimensional models $X$ can be a vector with correlations among its components, but different observations of this vector would still be independent of each other.\n","\n","Let's relax this. Assume the next state will depend (**only**) on the current state. In the travel analogy: don't sample countries independently, but travel (sample) along some biased paths.\n","\n","The future is only a function of the present (and some parameters):\n","\n","$$x_{t+1} = f(x_t, \\theta)$$\n","\n","This is similar to **deterministic** physical laws, but with added stochasticity. \n","\n","\n","A Markov Process generates a sequence (a Markov chain) of states: \n","$X = (X_0, X_1, \\ldots)$ where each $X_t$ is a random variable and\n","\n","\n","$$Pr(X_{t+1} | X_t, X_{t-1}, \\ldots X_1) = Pr(X_{t+1} | X_t) $$\n","\n","\n","Markov Chain is a **memory-less** stochastic process: the present state encodes all the history.\n","\n","In Statistics parlance: Given the Present, the Future is conditionally independent of the Past.\n","<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/MC_DeterministicStatistic.jpg\",  width=\"1000\">\n","</div>\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Fyg-forO9Po-"},"source":["## Some History "]},{"cell_type":"markdown","metadata":{"id":"KdjdfUP2GM41"},"source":["<div>\n","   <img src=\"https://upload.wikimedia.org/wikipedia/commons/7/70/AAMarkov.jpg\" align=\"right\" width=\"200\">\n","</div>\n","\n","Andrey Markov (1856-1922)\n","- study processes which are not iid\n","- Law of Large Numbers does not depend on iid assumption\n","- 1st Markov model: words with 2 states (consonant, vowel)"]},{"cell_type":"markdown","metadata":{"id":"0HOoAVuGZJmg"},"source":["## A travel story"]},{"cell_type":"markdown","metadata":{"id":"uVaaqDhjbgbN"},"source":["<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/MC_TravelStory.jpg\",  width=\"600\">\n","</div>\n"]},{"cell_type":"markdown","metadata":{"id":"4z2ov-288c2t"},"source":["# Representations"]},{"cell_type":"markdown","metadata":{"id":"7mx8fxkO88_D"},"source":["## Encodings"]},{"cell_type":"markdown","metadata":{"id":"0zEqzjfz9EXr"},"source":["In this course we will assume that possible values for states $X_t$ are *discrete*. There are different possible **encodings**: \n","- {0,1,2,3}\n","- {A,B,C,D} or {A,C,G,T}\n","- {00, 01, 10, 11}\n","- ...\n","\n","For computational convenience we often use integers, possibly with an added dictionary when necessary."]},{"cell_type":"markdown","metadata":{"id":"dNVuyZV3-QO-"},"source":["## The Markov chain"]},{"cell_type":"markdown","metadata":{"id":"mbYQXaRo-mR5"},"source":["<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/MC_MarkovChain.jpg\",  width=\"1000\">\n","</div>\n"]},{"cell_type":"markdown","metadata":{"id":"JgsweiXW8xGW"},"source":["## The State graph"]},{"cell_type":"markdown","metadata":{"id":"ZEqqJZk69DB2"},"source":["An image says a thousand words:\n","\n","<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/MC_StateGraph.jpg\" width=\"1000\">\n","</div>\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"azQ40Ooy-dsU"},"source":["## The transition matrix"]},{"cell_type":"markdown","metadata":{"id":"80wGwkt7_XVL"},"source":["Matrices help for actual computation:"]},{"cell_type":"markdown","metadata":{"id":"lB-uZoBR-YaC"},"source":["$$\n","P = \\begin{bmatrix} \n","0.8   &  0.2 \\\\ \n","0.1   &  0.9 \n","\\end{bmatrix} \n","$$"]},{"cell_type":"markdown","metadata":{"id":"p_2Na1Cu7f9V"},"source":["## Check:\n","\n","Are you comfortable to swap between the 3 representations? We'll use them a lot.\n","\n","---\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"5G39eb87fCW1"},"source":["## Discussion\n","Suggest other examples of Markov chains.\n","\n","- What are the observables and what are transitions ?\n","- How would you represent this system?\n","- Are there examples of sequences that **cannot** be described by simple transitions?\n","\n","Inspirational link: https://en.wikipedia.org/wiki/Examples_of_Markov_chains"]},{"cell_type":"markdown","metadata":{"id":"0XIsJC2bVYBY"},"source":["## Polls:\n","\n","\n","**Example 1:** drawing coloured balls from a mixed bag. Colour=random variable=state.\n","1. without replacement --> Markovian?\n","2. with replacement --> Markovian? \n","\n","**Example 2:** from physics/mechanics: Consider flying object at time t. What is the state of the object?\n","1. state=position --> Markovian?\n","2. state=position+velocity --> Markovian?"]},{"cell_type":"markdown","metadata":{"id":"zXnkzWLo4LgU"},"source":["# Markov Chains with Python"]},{"cell_type":"markdown","metadata":{"id":"JCyWsB0VW1Xk"},"source":["### Define Transition Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Du2t2exehhpl"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"52Pdr6f2Otnn"},"outputs":[],"source":["P = [[0.8, 0.2], [0.1, 0.9]]"]},{"cell_type":"markdown","metadata":{"id":"YiQpbb4D9-mM"},"source":["**Question**: What type of data structure is P: List, Set, Tuple ?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":210,"status":"ok","timestamp":1654617620113,"user":{"displayName":"Thomas Manke","userId":"17591636328965298454"},"user_tz":-120},"id":"BZqoP8zI-QUw","outputId":"725dceb1-cb62-4417-b54b-4959d9077609"},"outputs":[{"name":"stdout","output_type":"stream","text":["Edit before executing\n"]}],"source":["%%script echo Edit before executing\n","print('type of P   ',  ... )\n","print('length of P ', ... )"]},{"cell_type":"markdown","metadata":{"id":"zyi9b_Q0-iMs"},"source":["Let's convert $P$ into numpy array:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":218,"status":"ok","timestamp":1654617626768,"user":{"displayName":"Thomas Manke","userId":"17591636328965298454"},"user_tz":-120},"id":"XVZk0d30-ahV","outputId":"d24c7ff5-598e-4490-d18f-07f7d61907f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["dimensionality of P:  2\n","shape of P:           (2, 2)\n"]}],"source":["P = np.array(P)\n","print('dimensionality of P: ', P.ndim)\n","print('shape of P:          ', P.shape)"]},{"cell_type":"markdown","metadata":{"id":"EuGEbY0pQU_0"},"source":["**Defensive Programming:** Check Transition Matrix $P$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8eqIhfAw5OiP"},"outputs":[],"source":["assert P.shape[0]==P.shape[1],         \"P should be a squared matrix\"\n","assert np.allclose( P.sum(axis=1), 1), \"P should be a stochastic matrix\""]},{"cell_type":"markdown","metadata":{"id":"2FjAgzuw5waw"},"source":["**Task (10 min):**:\n","\n","Chose a state $X$, then chose (probabilistically) the next state with probability given by the transition matrix $P$.\n","\n","Hint1: use integer encoding of state variable\n","\n","Hint2: use np.random.choice()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":208,"status":"ok","timestamp":1654618119729,"user":{"displayName":"Thomas Manke","userId":"17591636328965298454"},"user_tz":-120},"id":"SPJ-_-_i6hry","outputId":"955e68d4-9f94-44f7-d854-62dcb76d0d7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Edit before executing\n"]}],"source":["%%script echo Edit before executing\n","np.random.seed(42)         # optional (for determinisitic reproducibility)\n","X0= [... your choice ...]  # chose state, consider you possible choices\n","X1= [... chose next from Markov Model ...]\n"]},{"cell_type":"markdown","metadata":{"id":"3mmPrS2Yogyx"},"source":["### Generate Sequences\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wZwfl9EZ7aka"},"source":["**Task 10 min**: Repeat the ideas above to generate a sequence of 100 observations from Markov Model $P$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Db8ab-uIO_Tk"},"outputs":[],"source":["%%script echo Edit before executing\n","np.random.seed(42)\n","ns= ....     # obtain number of states from P\n","X= ....      # pick initial state manually\n","L1 = [ X ]   # add X to sequence of states\n","\n","# loop over 100 times\n","for [ .... ]:\n","  X = [ ... pick ...]  # pick next state from current state\n","  L1.append(X)         # append it to list\n","\n","print(*L1, sep='')     # print sequence"]},{"cell_type":"markdown","metadata":{"id":"fbb2awY5OuP6"},"source":["Congratulations! You have just generated your first Markov chain !"]},{"cell_type":"markdown","metadata":{"id":"fjCsWQSZWWMv"},"source":["**Poll:** What happens if you comment out the first line? (Think first, then try)"]},{"cell_type":"markdown","metadata":{"id":"izBiVnlShu0J"},"source":["---\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"rgPgo9zgKE4_"},"source":["**Task (10min):** \n","\n","We will need the sequence generation again. Turn it into a function.\n","\n","Include the initial state $s$ and the maximal time $T$ as parameters with default values ($s=0, T=100$)\n","\n","Test the function for the $P$ above"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wxd1e_VwKRM0"},"outputs":[],"source":["%%script echo Edit before executing\n","def generate_sequence(P, s=0, T=100):\n","\n","[ ... add code here ...]\n","\n","  return L"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XC9vqwifLFbr"},"outputs":[],"source":["%%script echo Ensure that generate_sequence() is defined\n","X=generate_sequence(P)\n","print(*X, sep='')"]},{"cell_type":"markdown","metadata":{"id":"peASSKM3MIsN"},"source":["**Discussion:** The above example is very simplistic. Which changes would you suggest to make the function more robust?"]},{"cell_type":"markdown","metadata":{"id":"795mMOPf9TSi"},"source":["**Exercise (10 min)**:\n","\n","Repeat the above for a Markov chain with 3 states and transition matrix (or some other choice)\n","\n","$$P_3 = \\begin{bmatrix}\n","0.8 & 0.1 & 0.1 \\\\\n","0.2 & 0.7 & 0.1 \\\\\n","0.1 & 0.2 & 0.7 \n","\\end{bmatrix} $$\n"," </div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aC70Fxo_-T50"},"outputs":[],"source":["%%script echo Edit before executing\n","P3 = [ ... edit here ...]\n","\n","X = generate_sequence(P3)\n","print(*X, sep='')"]},{"cell_type":"markdown","metadata":{"id":"PbkcT6b3-0Aa"},"source":["## An animation"]},{"cell_type":"markdown","metadata":{"id":"lmA_kziMXWuM"},"source":["There is a beautiful animation & visualization, but please be aware that they may not render well on all systems.\n","\n","- Visualization: https://setosa.io/markov/index.html\n","- Explanation: https://setosa.io/ev/markov-chains\n","\n"]},{"cell_type":"markdown","metadata":{"id":"clZIKp4O7cR0"},"source":["## Coin throws"]},{"cell_type":"markdown","metadata":{"id":"DHPpAPQa7jNK"},"source":["Throwing a *biased* coin is usually modelled as a Bernoulli process with success probability $p$ - i.e. the probability of obtaining heads.\n","$$\n","Pr(X=Heads) = p\n","$$\n","\n","For an *unbiased* coin: $p=0.5$.\n","\n","However, this can also be formulated as a Markov Process.\n","Let's encode the two possible states as (heads=0) and (tails=1) for numerical convenience - see figure."]},{"cell_type":"markdown","metadata":{"id":"aeThbM3z93a2"},"source":["**Task (10 min):**\n","\n","Write down the corresponding transition matrix $P$ for a biased coin and simulate the coin throwing experiment - e.g. 50 throws for your favorite $p$."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1652253618358,"user":{"displayName":"Thomas Manke","userId":"17591636328965298454"},"user_tz":-120},"id":"fW_RV_4O-gGF","outputId":"3f287ffd-5d75-47a9-bbf8-cadafa42b536"},"outputs":[{"name":"stdout","output_type":"stream","text":["010100101000111110000000110011101011101101111011110\n"]}],"source":["%%script echo Edit before executing\n","p = [ ... your choice ...]\n","P = np.array(\n","   [ ... edit here ...]\n",")\n","X = generate_sequence(P, T=50)\n","print(*X, sep='')"]},{"cell_type":"markdown","metadata":{"id":"_40lQpsHCca_"},"source":["# References\n","\n","- https://brilliant.org/wiki/markov-chains/\n","\n","- John Tsitsiklis (MIT, Prob. Systems): https://www.youtube.com/watch?v=IkbkEtOOC1Y\n","- Joseph Blitzstein (Harvard, Stats110): https://www.youtube.com/watch?v=8AJPs3gvNlY\n"]}],"metadata":{"colab":{"collapsed_sections":["4z2ov-288c2t","7mx8fxkO88_D","azQ40Ooy-dsU","_40lQpsHCca_"],"provenance":[]},"kernelspec":{"display_name":"Python 3.10.7 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
