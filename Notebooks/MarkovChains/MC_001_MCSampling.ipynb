{"cells":[{"cell_type":"markdown","source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/thomasmanke/ABS/blob/main/Notebooks/MarkovChains/MC_001_MCSampling.ipynb)"],"metadata":{"id":"FkekGi6um5xh"}},{"cell_type":"markdown","metadata":{"id":"E1DFkwtNry9v"},"source":["# Markov Chain Sampling"]},{"cell_type":"markdown","source":["## Background "],"metadata":{"id":"9AxEWXawELse"}},{"cell_type":"markdown","metadata":{"id":"Y3ejd9auHyQT"},"source":["In the models discussed previously, all observations were sampled independently of each other, and from the same distribution (*iid*): \n","\n","$$X \\propto N(\\mu, \\sigma^2)$$\n","\n","In higher dimensional models $X$ can be a vector with correlations among its components, but different observations of this vector would still be independent of each other.\n","\n","Let's relax this. Assume the next state will depend (**only**) on the current state. In the travel analogy: don't sample countries independently, but travel (sample) along some biased paths.\n","\n","The future is only a function of the present (and some parameters):\n","\n","$$x_{t+1} = f(x_t, \\theta)$$\n","\n","This is similar to **deterministic** physical laws, but with added stochasticity. \n","\n","\n","A Markov Process generates a sequence (a Markov chain) of states: \n","$X = (X_0, X_1, \\ldots)$ where each $X_t$ is a random variable and\n","\n","\n","$$Pr(X_{t+1} | X_t, X_{t-1}, \\ldots X_1) = Pr(X_{t+1} | X_t) $$\n","\n","\n","Markov Chain is a **memory-less** stochastic process: the present state encodes all the history.\n","\n","In Statistics parlance: Given the Present, the Future is conditionally independent of the Past.\n","<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/MC_DeterministicStatistic.jpg\",  width=\"1000\">\n","</div>\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","source":["## Some History "],"metadata":{"id":"Fyg-forO9Po-"}},{"cell_type":"markdown","source":["<div>\n","   <img src=\"https://upload.wikimedia.org/wikipedia/commons/7/70/AAMarkov.jpg\" align=\"right\" width=\"200\">\n","</div>\n","\n","Andrey Markov (1856-1922)\n","- study processes which are not iid\n","- Law of Large Numbers does not depend on iid assumption\n","- 1st Markov model: words with 2 states (consonant, vowel)"],"metadata":{"id":"KdjdfUP2GM41"}},{"cell_type":"markdown","source":["## A travel story"],"metadata":{"id":"0HOoAVuGZJmg"}},{"cell_type":"markdown","source":["<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/MC_TravelStory.jpg\",  width=\"600\">\n","</div>\n"],"metadata":{"id":"uVaaqDhjbgbN"}},{"cell_type":"markdown","source":["# Representations"],"metadata":{"id":"4z2ov-288c2t"}},{"cell_type":"markdown","source":["## Encodings"],"metadata":{"id":"7mx8fxkO88_D"}},{"cell_type":"markdown","source":["In this course we will assume that possible values for states $X_t$ are *discrete*. There are different possible **encodings**: \n","- {0,1,2,3}\n","- {A,B,C,D} or {A,C,G,T}\n","- {00, 01, 10, 11}\n","- ...\n","\n","For computational convenience we often use integers, possibly with an added dictionary when necessary."],"metadata":{"id":"0zEqzjfz9EXr"}},{"cell_type":"markdown","source":["## The Markov chain"],"metadata":{"id":"dNVuyZV3-QO-"}},{"cell_type":"markdown","source":["<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/MC_MarkovChain.jpg\",  width=\"1000\">\n","</div>\n"],"metadata":{"id":"mbYQXaRo-mR5"}},{"cell_type":"markdown","source":["## The State graph"],"metadata":{"id":"JgsweiXW8xGW"}},{"cell_type":"markdown","source":["An image says a thousand words:\n","\n","<div>\n","   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/MC_StateGraph.jpg\" width=\"1000\">\n","</div>\n","\n","\n","\n"],"metadata":{"id":"ZEqqJZk69DB2"}},{"cell_type":"markdown","source":["## The transition matrix"],"metadata":{"id":"azQ40Ooy-dsU"}},{"cell_type":"markdown","source":["Matrices help for actual computation:"],"metadata":{"id":"80wGwkt7_XVL"}},{"cell_type":"markdown","source":["$$\n","P = \\begin{bmatrix} \n","0.8   &  0.2 \\\\ \n","0.1   &  0.9 \n","\\end{bmatrix} \n","$$"],"metadata":{"id":"lB-uZoBR-YaC"}},{"cell_type":"markdown","source":["## The Trellis graph"],"metadata":{"id":"G70F7NMH8keG"}},{"cell_type":"markdown","source":["Example for 4 different states:\n","<div>\n","   <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/Convolutional_code_trellis_diagram.svg/2880px-Convolutional_code_trellis_diagram.svg.png\"  width=\"1000\">\n","</div>\n","\n","An observed sequence $X$ is a specific path (one of many possible) through the lattice diagram (shown in red)."],"metadata":{"id":"u1eP8VqX8odP"}},{"cell_type":"markdown","source":["## Check:\n","\n","Are you comfortable to swap between the 4 representations? We'll use them a lot.\n","\n","---\n","\n","---"],"metadata":{"id":"p_2Na1Cu7f9V"}},{"cell_type":"markdown","source":["## Discussion\n","Suggest other examples of Markov chains.\n","\n","- What are the observables and what are transitions ?\n","- How would you represent this system?\n","- Are there examples of sequences that **cannot** be described by simple transitions?\n","\n","Inspirational link: https://en.wikipedia.org/wiki/Examples_of_Markov_chains"],"metadata":{"id":"5G39eb87fCW1"}},{"cell_type":"markdown","source":["## Polls:\n","\n","\n","**Example 1:** drawing coloured balls from a mixed bag. Colour=random variable=state.\n","1. without replacement --> Markovian?\n","2. with replacement --> Markovian? \n","\n","**Example 2:** from physics/mechanics: Consider flying object at time t. What is the state of the object?\n","1. state=position --> Markovian?\n","2. state=position+velocity --> Markovian?"],"metadata":{"id":"0XIsJC2bVYBY"}},{"cell_type":"markdown","metadata":{"id":"zXnkzWLo4LgU"},"source":["# Markov Chains with Python"]},{"cell_type":"markdown","source":["### Define Transition Matrix"],"metadata":{"id":"JCyWsB0VW1Xk"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt"],"metadata":{"id":"Du2t2exehhpl","executionInfo":{"status":"ok","timestamp":1654617557345,"user_tz":-120,"elapsed":6,"user":{"displayName":"Thomas Manke","userId":"17591636328965298454"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"52Pdr6f2Otnn","executionInfo":{"status":"ok","timestamp":1654617568269,"user_tz":-120,"elapsed":232,"user":{"displayName":"Thomas Manke","userId":"17591636328965298454"}}},"outputs":[],"source":["P = [[0.8, 0.2], [0.1, 0.9]]"]},{"cell_type":"markdown","metadata":{"id":"YiQpbb4D9-mM"},"source":["**Question**: What type of data structure is P: List, Set, Tuple ?"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"BZqoP8zI-QUw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654617620113,"user_tz":-120,"elapsed":210,"user":{"displayName":"Thomas Manke","userId":"17591636328965298454"}},"outputId":"725dceb1-cb62-4417-b54b-4959d9077609"},"outputs":[{"output_type":"stream","name":"stdout","text":["Edit before executing\n"]}],"source":["%%script echo Edit before executing\n","print('type of P   ',  ... )\n","print('length of P ', ... )"]},{"cell_type":"markdown","metadata":{"id":"zyi9b_Q0-iMs"},"source":["Let's convert $P$ into numpy array:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"XVZk0d30-ahV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654617626768,"user_tz":-120,"elapsed":218,"user":{"displayName":"Thomas Manke","userId":"17591636328965298454"}},"outputId":"d24c7ff5-598e-4490-d18f-07f7d61907f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["dimensionality of P:  2\n","shape of P:           (2, 2)\n"]}],"source":["P = np.array(P)\n","print('dimensionality of P: ', P.ndim)\n","print('shape of P:          ', P.shape)"]},{"cell_type":"markdown","metadata":{"id":"EuGEbY0pQU_0"},"source":["**Defensive Programming:** Check Transition Matrix $P$"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"8eqIhfAw5OiP","executionInfo":{"status":"ok","timestamp":1654617636221,"user_tz":-120,"elapsed":225,"user":{"displayName":"Thomas Manke","userId":"17591636328965298454"}}},"outputs":[],"source":["  assert P.shape[0]==P.shape[1],         \"P should be a squared matrix\"\n","  assert np.allclose( P.sum(axis=1), 1), \"P should be a stochastic matrix\""]},{"cell_type":"markdown","source":["**Task (10 min):**:\n","\n","Chose a state $X$, then chose (probabilistically) the next state with probability given by the transition matrix $P$.\n","\n","Hint1: use integer encoding of state variable\n","\n","Hint2: use np.random.choice()"],"metadata":{"id":"2FjAgzuw5waw"}},{"cell_type":"code","source":["%%script echo Edit before executing\n","np.random.seed(42)         # optional (for determinisitic reproducibility)\n","X0= [... your choice ...]  # chose state, consider you possible choices\n","X1= [... chose next from Markov Model ...]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SPJ-_-_i6hry","executionInfo":{"status":"ok","timestamp":1654618119729,"user_tz":-120,"elapsed":208,"user":{"displayName":"Thomas Manke","userId":"17591636328965298454"}},"outputId":"955e68d4-9f94-44f7-d854-62dcb76d0d7b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Edit before executing\n"]}]},{"cell_type":"markdown","metadata":{"id":"3mmPrS2Yogyx"},"source":["### Generate Sequences\n","\n","\n"]},{"cell_type":"markdown","source":["**Task 10 min**: Repeat the ideas above to generate a sequence of 100 observations from Markov Model $P$"],"metadata":{"id":"wZwfl9EZ7aka"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Db8ab-uIO_Tk"},"outputs":[],"source":["%%script echo Edit before executing\n","np.random.seed(42)\n","ns= ....     # obtain number of states from P\n","X= ....      # pick initial state manually\n","L1 = [ X ]   # add X to sequence of states\n","\n","# loop over 100 times\n","for [ .... ]:\n","  X = [ ... pick ...]  # pick next state from current state\n","  L1.append(X)         # append it to list\n","\n","print(*L1, sep='')     # print sequence"]},{"cell_type":"markdown","metadata":{"id":"fbb2awY5OuP6"},"source":["Congratulations! You have just generated your first Markov chain !"]},{"cell_type":"markdown","metadata":{"id":"fjCsWQSZWWMv"},"source":["**Poll:** What happens if you comment out the first line? (Think first, then try)"]},{"cell_type":"markdown","source":["---\n","\n","---\n"],"metadata":{"id":"izBiVnlShu0J"}},{"cell_type":"markdown","metadata":{"id":"rgPgo9zgKE4_"},"source":["**Task (10min):** \n","\n","We will need the sequence generation again. Turn it into a function.\n","\n","Include the initial state $s$ and the maximal time $T$ as parameters with default values ($s=0, T=100$)\n","\n","Test the function for the $P$ above"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wxd1e_VwKRM0"},"outputs":[],"source":["%%script echo Edit before executing\n","def generate_sequence(P, s=0, T=100):\n","\n","[ ... add code here ...]\n","\n","  return L"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XC9vqwifLFbr"},"outputs":[],"source":["X=generate_sequence(P)\n","print(*X, sep='')"]},{"cell_type":"markdown","metadata":{"id":"peASSKM3MIsN"},"source":["**Discussion:** The above example is very simplistic. Which changes would you suggest to make the function more robust?"]},{"cell_type":"markdown","metadata":{"id":"795mMOPf9TSi"},"source":["<div class=\"alert alert-block alert-warning\">\n","\n","**Exercise (10 min)**:\n","\n","Repeat the above for a Markov chain with 3 states and transition matrix (or some other choice)\n","\n","$$P_3 = \\begin{bmatrix}\n","0.8 & 0.1 & 0.1 \\\\\n","0.2 & 0.7 & 0.1 \\\\\n","0.1 & 0.2 & 0.7 \n","\\end{bmatrix} $$\n"," </div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aC70Fxo_-T50"},"outputs":[],"source":["%%script echo Edit before executing\n","P3 = [ ... edit here ...]\n","\n","X = generate_sequence(P3)\n","print(*X, sep='')"]},{"cell_type":"markdown","metadata":{"id":"PbkcT6b3-0Aa"},"source":["## An animation"]},{"cell_type":"markdown","source":["There is a beautiful animation & visualization, but please be aware that they may not render well on all systems.\n","\n","- Visualization: https://setosa.io/markov/index.html\n","- Explanation: https://setosa.io/ev/markov-chains\n","\n"],"metadata":{"id":"lmA_kziMXWuM"}},{"cell_type":"markdown","source":["## Coin throws"],"metadata":{"id":"clZIKp4O7cR0"}},{"cell_type":"markdown","source":["Throwing a *biased* coin is usually modelled as a Bernoulli process with success probability $p$ - i.e. the probability of obtaining heads.\n","$$\n","Pr(X=Heads) = p\n","$$\n","\n","For an *unbiased* coin: $p=0.5$.\n","\n","However, this can also be formulated as a Markov Process.\n","Let's encode the two possible states as (heads=0) and (tails=1) for numerical convenience - see figure."],"metadata":{"id":"DHPpAPQa7jNK"}},{"cell_type":"markdown","source":["**Task (10 min):**\n","\n","Write down the corresponding transition matrix $P$ for a biased coin and simulate the coin throwing experiment - e.g. 50 throws for your favorite $p$."],"metadata":{"id":"aeThbM3z93a2"}},{"cell_type":"code","source":["%%script echo Edit before executing\n","p = [ ... your choice ...]\n","P = np.array(\n","   [ ... edit here ...]\n",")\n","X = generate_sequence(P, T=50)\n","print(*X, sep='')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fW_RV_4O-gGF","executionInfo":{"status":"ok","timestamp":1652253618358,"user_tz":-120,"elapsed":2,"user":{"displayName":"Thomas Manke","userId":"17591636328965298454"}},"outputId":"3f287ffd-5d75-47a9-bbf8-cadafa42b536"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["010100101000111110000000110011101011101101111011110\n"]}]},{"cell_type":"markdown","metadata":{"id":"_40lQpsHCca_"},"source":["# References\n","\n","- https://brilliant.org/wiki/markov-chains/\n","\n","- John Tsitsiklis (MIT, Prob. Systems): https://www.youtube.com/watch?v=IkbkEtOOC1Y\n","- Joseph Blitzstein (Harvard, Stats110): https://www.youtube.com/watch?v=8AJPs3gvNlY\n"]}],"metadata":{"colab":{"collapsed_sections":["4z2ov-288c2t","7mx8fxkO88_D","azQ40Ooy-dsU","_40lQpsHCca_"],"name":"MC_001_MCSampling.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":0}